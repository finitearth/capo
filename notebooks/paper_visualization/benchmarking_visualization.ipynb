{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmarking Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from capo.analysis.utils import (\n",
    "    get_results,\n",
    "    # aggregate_results,\n",
    "    # get_prompt_scores,\n",
    "    generate_comparison_table,\n",
    ")\n",
    "from capo.analysis.visualizations import (\n",
    "    # plot_population_scores,\n",
    "    # plot_population_members,\n",
    "    plot_population_scores_comparison,\n",
    "    plot_length_score,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPTIMS = [\"CAPO\", \"EvoPromptGA\", \"OPRO\", \"PromptWizard\", \"init\"]\n",
    "OPTIMS_NO_WIZ = [\"CAPO\", \"EvoPromptGA\", \"OPRO\", \"init\"]\n",
    "OPTIMS_NO_SING = [\"CAPO\", \"EvoPromptGA\", \"OPRO\"]\n",
    "DATASETS = [\"sst-5\", \"agnews\", \"copa\", \"gsm8k\", \"subj\"]\n",
    "MODELS = [\"llama\", \"mistral\", \"qwen\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: red\">Open question: use aggregation \"mean\" or \"best_train\" for optimization curves</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mistral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_comparison_table(DATASETS, OPTIMS, \"mistral\", path_prefix=\"../../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_population_scores_comparison(\n",
    "    \"sst-5\",\n",
    "    \"mistral\",\n",
    "    OPTIMS,\n",
    "    agg=\"mean\",\n",
    "    plot_seeds=False,\n",
    "    plot_stddev=True,\n",
    "    x_col=\"input_tokens_cum\",\n",
    "    path_prefix=\"../..\",\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_population_scores_comparison(\n",
    "    \"agnews\",\n",
    "    \"mistral\",\n",
    "    OPTIMS,\n",
    "    agg=\"mean\",\n",
    "    plot_seeds=False,\n",
    "    plot_stddev=True,\n",
    "    x_col=\"input_tokens_cum\",\n",
    "    path_prefix=\"../..\",\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_population_scores_comparison(\n",
    "    \"subj\",\n",
    "    \"mistral\",\n",
    "    OPTIMS,\n",
    "    agg=\"mean\",\n",
    "    plot_seeds=False,\n",
    "    plot_stddev=True,\n",
    "    x_col=\"input_tokens_cum\",\n",
    "    path_prefix=\"../..\",\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_population_scores_comparison(\n",
    "    \"gsm8k\",\n",
    "    \"mistral\",\n",
    "    OPTIMS,\n",
    "    agg=\"mean\",\n",
    "    plot_seeds=False,\n",
    "    plot_stddev=True,\n",
    "    x_col=\"input_tokens_cum\",\n",
    "    path_prefix=\"../..\",\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_population_scores_comparison(\n",
    "    \"copa\",\n",
    "    \"mistral\",\n",
    "    OPTIMS,\n",
    "    agg=\"mean\",\n",
    "    plot_seeds=False,\n",
    "    plot_stddev=True,\n",
    "    x_col=\"input_tokens_cum\",\n",
    "    path_prefix=\"../..\",\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Qwen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_comparison_table(DATASETS, OPTIMS, \"qwen\", path_prefix=\"../../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_population_scores_comparison(\n",
    "    \"sst-5\",\n",
    "    \"mistral\",\n",
    "    OPTIMS_NO_WIZ,\n",
    "    agg=\"mean\",\n",
    "    plot_seeds=False,\n",
    "    plot_stddev=True,\n",
    "    x_col=\"input_tokens_cum\",\n",
    "    path_prefix=\"../..\",\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_population_scores_comparison(\n",
    "    \"agnews\",\n",
    "    \"mistral\",\n",
    "    OPTIMS_NO_WIZ,\n",
    "    agg=\"mean\",\n",
    "    plot_seeds=False,\n",
    "    plot_stddev=True,\n",
    "    x_col=\"input_tokens_cum\",\n",
    "    path_prefix=\"../..\",\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_population_scores_comparison(\n",
    "    \"subj\",\n",
    "    \"mistral\",\n",
    "    OPTIMS,\n",
    "    agg=\"mean\",\n",
    "    plot_seeds=False,\n",
    "    plot_stddev=True,\n",
    "    x_col=\"input_tokens_cum\",\n",
    "    path_prefix=\"../..\",\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_population_scores_comparison(\n",
    "    \"gsm8k\",\n",
    "    \"mistral\",\n",
    "    OPTIMS,\n",
    "    agg=\"mean\",\n",
    "    plot_seeds=False,\n",
    "    plot_stddev=True,\n",
    "    x_col=\"input_tokens_cum\",\n",
    "    path_prefix=\"../..\",\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_population_scores_comparison(\n",
    "    \"copa\",\n",
    "    \"mistral\",\n",
    "    OPTIMS_NO_WIZ,\n",
    "    agg=\"mean\",\n",
    "    plot_seeds=False,\n",
    "    plot_stddev=True,\n",
    "    x_col=\"input_tokens_cum\",\n",
    "    path_prefix=\"../..\",\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Llama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_comparison_table(DATASETS, OPTIMS, \"llama\", path_prefix=\"../../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_population_scores_comparison(\n",
    "    \"sst-5\",\n",
    "    \"llama\",\n",
    "    OPTIMS_NO_WIZ,\n",
    "    agg=\"mean\",\n",
    "    plot_seeds=False,\n",
    "    plot_stddev=True,\n",
    "    x_col=\"input_tokens_cum\",\n",
    "    path_prefix=\"../..\",\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_population_scores_comparison(\n",
    "    \"agnews\",\n",
    "    \"llama\",\n",
    "    OPTIMS_NO_WIZ,\n",
    "    agg=\"mean\",\n",
    "    plot_seeds=False,\n",
    "    plot_stddev=True,\n",
    "    x_col=\"input_tokens_cum\",\n",
    "    path_prefix=\"../..\",\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_population_scores_comparison(\n",
    "    \"subj\",\n",
    "    \"llama\",\n",
    "    OPTIMS,\n",
    "    agg=\"mean\",\n",
    "    plot_seeds=False,\n",
    "    plot_stddev=True,\n",
    "    x_col=\"input_tokens_cum\",\n",
    "    path_prefix=\"../..\",\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_population_scores_comparison(\n",
    "    \"gsm8k\",\n",
    "    \"llama\",\n",
    "    OPTIMS,\n",
    "    agg=\"mean\",\n",
    "    plot_seeds=False,\n",
    "    plot_stddev=True,\n",
    "    x_col=\"input_tokens_cum\",\n",
    "    path_prefix=\"../..\",\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_population_scores_comparison(\n",
    "    \"copa\",\n",
    "    \"llama\",\n",
    "    OPTIMS_NO_WIZ,\n",
    "    agg=\"mean\",\n",
    "    plot_seeds=True,\n",
    "    plot_stddev=True,\n",
    "    x_col=\"input_tokens_cum\",\n",
    "    path_prefix=\"../..\",\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Candidates for main paper\n",
    "- GSM8K (because its most relevant dataset)\n",
    "- Subj using qwen (because it has beautiful curves)\n",
    "\n",
    "Takeaways:\n",
    "- PromptWizard's performance is highly dependend on model used (=> strict templates!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in MODELS:\n",
    "    print(f\"Model: {model}\")\n",
    "    display(generate_comparison_table(model=model, cutoff_tokens=1_000_000, path_prefix=\"../..\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in MODELS:\n",
    "    print(f\"Model: {model}\")\n",
    "    display(generate_comparison_table(model=model, cutoff_tokens=3_000_000, path_prefix=\"../../\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in MODELS:\n",
    "    print(f\"Model: {model}\")\n",
    "    display(generate_comparison_table(model=model, path_prefix=\"../..\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in DATASETS:\n",
    "    for model in MODELS:\n",
    "        plot_length_score(\n",
    "            dataset,\n",
    "            model,\n",
    "            OPTIMS,\n",
    "            x_col=\"prompt_len\",\n",
    "            score_col=\"test_score\",\n",
    "            log_scale=False,\n",
    "            path_prefix=\"../temp/res/\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=> maybe we are cost aware in the sense that we are evaluating the entire \"front\" (EvoPrompt and Opro are very short and Promptwizard very long)\n",
    "\n",
    "- promptwizard has extremly long prompts, that only sometimes can compete with competitors\n",
    "\n",
    "=> interesting for plotting: \n",
    "- subj using qwen or gsm8k using mistral => shows that we have a huge range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint as pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print best prompt per dataset, model, optimizer\n",
    "for dataset in DATASETS:\n",
    "    for model in MODELS:\n",
    "        for optim in OPTIMS:\n",
    "            print(f\"Dataset: {dataset}, Model: {model}, Optimizer: {optim}\")\n",
    "            df = get_results(\n",
    "                dataset=dataset,\n",
    "                model=model,\n",
    "                optim=optim,\n",
    "                # sort_by=\"test_score\",\n",
    "                # ascending=False,\n",
    "            )\n",
    "\n",
    "            if df.empty:\n",
    "                continue\n",
    "            p, s = df.nlargest(1, \"test_score\")[[\"prompt\", \"test_score\"]].values[0]\n",
    "            print(s)\n",
    "            print(\"'''\")\n",
    "            pp(p)\n",
    "            print(\"'''\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "capo can be very repetitive? (SST-5 mistral) potentially the crossover meta prompt has been misinterpreted (merge the two prompts) => however it is performing superior!\n",
    "\n",
    "subj for qwen and llama with capo has a crazy outlier to the top\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
