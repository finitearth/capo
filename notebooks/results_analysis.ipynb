{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "step",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "timestamp",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "input_tokens_meta_llm",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "output_tokens_meta_llm",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "input_tokens_downstream_llm",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "output_tokens_downstream_llm",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "time_elapsed",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "score",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "prompt",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "33a316ee-77aa-4b0f-b4ad-fbfa56ab290d",
       "rows": [
        [
         "0",
         "1",
         "2025-03-13 18:00:08.645871",
         "1424",
         "635",
         "161831",
         "29141",
         "125.999972",
         "0.7628458498023714",
         "Linguistic analysis: Examine the provided sentence and determine whether it's objective (factual, unbiased, could be verified) or subjective (opinion-based, contains judgments, emotions, or personal perspective). Your response should be formatted as <final_answer>objective</final_answer> or <final_answer>subjective</final_answer>.\n\nInput: years of guilt and sorrow tumble over each other as vince struggles to retain his sanity and understand who it is he is hoping to find alive .\nOutput: <final_answer> objective </final_answer>\n\nInput: she also has an ulcer and does n't get much sleep .\nOutput: <final_answer>objective</final_answer>\n\nInput: this bold and cathartic drama deserves to be experienced by those who cherish intimate dramas about individuals struggling against all odds to practice love , compassion , and forgiveness .\nOutput: <final_answer> subjective </final_answer>\n\nInput: "
        ],
        [
         "1",
         "1",
         "2025-03-13 18:00:08.645871",
         "1424",
         "635",
         "161831",
         "29141",
         "125.999972",
         "0.7323451910408433",
         "You are tasked with analyzing each sentence to determine whether it contains objective information (facts, measurable data) or subjective content (opinions, judgments, emotions). Read the sentence and classify it as either 'subjective' (containing opinions, judgments, or emotions) or 'objective' (presenting verifiable facts without personal bias). Your answer should be formatted as: <final_answer>your classification</final_answer>.\n\nInput: it 's a race against the clock as jay must convince kay -- who not only has no memory of his time spent with the agency , but is also the only person alive who has the expertise to save the galaxy -- to reunite with the mib before earth is destroyed completely .\nOutput: <final_answer> objective </final_answer>\n\nInput: this harrowing journey into combat hell vividly captures the chaotic insanity and personal tragedies that are all too abundant when human hatred spews forth unchecked .\nOutput: <final_answer>subjective</final_answer>\n\nInput: beers , who , when she 's given the right lines , can charm the paint off the wall . . . [ but ] the script goes wrong at several key junctures .\nOutput: <final_answer> subjective </final_answer>\n\nInput: "
        ],
        [
         "2",
         "1",
         "2025-03-13 18:00:08.645871",
         "1424",
         "635",
         "161831",
         "29141",
         "125.999972",
         "0.7204216073781292",
         "Task: Classify each sentence as either subjective or objective. Determine whether the sentence presents factual, verifiable information (objective) or expresses personal viewpoints, feelings, or judgments (subjective). Provide your answer in the format <final_answer>your_answer</final_answer>.\n\nInput: after a dream of a horrific car crash , kimberly helps save several people and causes another rift in death 's design , but this time its different , since alex walked off the plane death 's design did not only affect the survivors of flight 180 , but every single person they 've come in contact with , now how will they stop it ?\nOutput: <final_answer> objective </final_answer>\n\nInput: steve 's best friend , sean , on the other hand , has n't been so lucky .\nOutput: <final_answer> objective </final_answer>\n\nInput: completely creatively stillborn and executed in a manner that i 'm not sure could be a single iota worse . . . a soulless hunk of exploitative garbage .\nOutput: <final_answer> subjective </final_answer>\n\nInput: "
        ],
        [
         "3",
         "1",
         "2025-03-13 18:00:08.645871",
         "1424",
         "635",
         "161831",
         "29141",
         "125.999972",
         "0.6761528326745718",
         "Classify as objective (fact-based) or subjective (opinion-based). Answer within <final_answer> </final_answer>.\n\nInput: thekids will probably stay amused at the kaleidoscope of big , colorful characters . mom and dad can catch some quality naptime along the way .\nOutput: <final_answer> subjective </final_answer>\n\nInput: suffers from the lack of a compelling or comprehensible narrative . still , as a visual treat , the film is almost unsurpassed .\nOutput: <final_answer> subjective </final_answer>\n\nInput: after a dream of a horrific car crash , kimberly helps save several people and causes another rift in death 's design , but this time its different , since alex walked off the plane death 's design did not only affect the survivors of flight 180 , but every single person they 've come in contact with , now how will they stop it ?\nOutput: <final_answer> objective </final_answer>\n\nInput: "
        ],
        [
         "4",
         "1",
         "2025-03-13 18:00:08.645871",
         "1424",
         "635",
         "161831",
         "29141",
         "125.999972",
         "0.6573122529644271",
         "Subjectivity analysis task: Examine the sentence and determine if it conveys factual information (objective) or personal opinions/feelings (subjective). Format your answer as <final_answer>objective</final_answer> or <final_answer>subjective</final_answer>.\n\nInput: as fran 's requests become more peculiar , chep is thrown into increasingly bizarre situations .\nOutput: <final_answer> objective </final_answer>\n\nInput: . . . comes alive only when it switches gears to the sentimental .\nOutput: <final_answer> subjective </final_answer>\n\nInput: entwined with maggie 's search for hope , the film explores her interaction with her family and friends .\nOutput: To determine whether the sentence conveates factual information or personal opinions/feellings, we need to analyze the content.\n\nThe sentence describes a film that explores a character's interactions with her family and friends. This description is factual and objective, as it describes events and relationships without expressing personal opinions or feelings.\n\n<final_answer>objective</final_answer>\n\nInput: "
        ],
        [
         "5",
         "1",
         "2025-03-13 18:00:08.645871",
         "1424",
         "635",
         "161831",
         "29141",
         "125.999972",
         "0.6409749670619237",
         "Sentence classification task: Does the sentence state facts (objective) or express opinions/feelings (subjective)? Provide your answer using the format <final_answer>your_answer</final_answer>.\n\nInput: a movie that will surely be profane , politically charged music to the ears of cho 's fans .\nOutput: <final_answer> subjective </final_answer>\n\nInput: ronnie schwann , a young man regarded as `` slow , `` has affections for sarah , a young woman who stays at hope house , a facility for the mentally ill .\nOutput: <final_answer>objective</final_answer>\n\nInput: "
        ],
        [
         "6",
         "1",
         "2025-03-13 18:00:08.645871",
         "1424",
         "635",
         "161831",
         "29141",
         "125.999972",
         "0.6371541501976281",
         "Determine whether each sentence is subjective or objective. Analyze the language to decide if the sentence is objective (factual, unbiased, verifiable) or subjective (opinion-based, includes judgments, emotions, or personal perspective). Provide your one-word answer within <final_answer> </final_answer>.\n\n\n\nInput: "
        ],
        [
         "7",
         "1",
         "2025-03-13 18:00:08.645871",
         "1424",
         "635",
         "161831",
         "29141",
         "125.999972",
         "0.6345191040843214",
         "Analyze the given sentence to determine whether it presents an objective statement (factual, unbiased information that can be verified) or a subjective statement (personal opinions, judgments, or emotions that may vary from person to person). Identify whether the sentence conveates facts (objective) or expresses opinions/feelings (subjective). Provide your answer using the format <final_answer>your_answer</final_answer>.\n\nInput: a documentary seven years in the making about women in the film business and how they balance , children , love lives and career -- or how they do n't .\nOutput: <final_answer> objective </final_answer>\n\nInput: ronnie schwann , a young man regarded as `` slow , `` has affections for sarah , a young woman who stays at hope house , a facility for the mentally ill .\nOutput: <final_answer>objective</final_answer>\n\nInput: well , jason 's gone to manhattan and hell , i guess a space station in the year 2455 can be crossed off the list of ideas for the inevitable future sequels ( hey , do n't shoot the messenger ) .\nOutput: <final_answer> subjective </final_answer>\n\nInput: "
        ],
        [
         "8",
         "1",
         "2025-03-13 18:00:08.645871",
         "1424",
         "635",
         "161831",
         "29141",
         "125.999972",
         "0.6166666666666669",
         "Using your understanding of subjectivity vs. objectivity in language, determine if the given sentence is objective (states facts, provides information without personal bias) or subjective (expresses opinions, emotions, or personal judgments). Place your classification between the <final_answer> </final_answer> tags.\n\nInput: huh is taken into custody after kang shoots and wounds him at the scene of the crime .\nOutput: <final_answer> objective </final_answer>\n\nInput: the stars may be college kids , but the subject matter is as adult as you can get : the temptations of the flesh are unleashed by a slightly crazed , overtly determined young woman and a one-night swim turns into an ocean of trouble .\nOutput: To determine whether the given sentence is objective or subjective, we need to analyze the content and the tone.\n\nThe sentence describes a scenario involving college students and their experiences, which includes themes of temptation, determination, and trouble. The language used is descriptive and includes emotional and subjective elements such as \"temptations of the flesh,\" \"crazed,\" \"determined,\" and \"ocean of trouble.\" These elements suggest personal judgments and emotions, which are subjective.\n\n<final_answer>subjective</final_answer>\n\nInput: "
        ],
        [
         "9",
         "1",
         "2025-03-13 18:00:08.645871",
         "1424",
         "635",
         "161831",
         "29141",
         "125.999972",
         "0.6052042160737812",
         "Read the following sentence and classify it as either 'subjective' (containing opinions, judgments, or emotions) or 'objective' (presenting verifiable facts without personal bias). Your answer must be formatted as: <final_answer>your classification</final_answer>\n\n\n\nInput: "
        ],
        [
         "10",
         "2",
         "2025-03-13 18:04:06.732074",
         "1627",
         "880",
         "568037",
         "140056",
         "238.084428",
         "0.6918501788067006",
         "Task: Classify each sentence as either subjective or objective. Determine whether the sentence presents factual, verifiable information (objective) or expresses personal viewpoints, feelings, or judgments (subjective). Provide your answer in the format <final_answer>your_answer</final_answer>.\n\nInput: after a dream of a horrific car crash , kimberly helps save several people and causes another rift in death 's design , but this time its different , since alex walked off the plane death 's design did not only affect the survivors of flight 180 , but every single person they 've come in contact with , now how will they stop it ?\nOutput: <final_answer> objective </final_answer>\n\nInput: steve 's best friend , sean , on the other hand , has n't been so lucky .\nOutput: <final_answer> objective </final_answer>\n\nInput: completely creatively stillborn and executed in a manner that i 'm not sure could be a single iota worse . . . a soulless hunk of exploitative garbage .\nOutput: <final_answer> subjective </final_answer>\n\nInput: "
        ],
        [
         "11",
         "2",
         "2025-03-13 18:04:06.732074",
         "1627",
         "880",
         "568037",
         "140056",
         "238.084428",
         "0.6914172783738002",
         "Linguistic analysis: Examine the provided sentence and determine whether it's objective (factual, unbiased, could be verified) or subjective (opinion-based, contains judgments, emotions, or personal perspective). Your response should be formatted as <final_answer>objective</final_answer> or <final_answer>subjective</final_answer>.\n\nInput: years of guilt and sorrow tumble over each other as vince struggles to retain his sanity and understand who it is he is hoping to find alive .\nOutput: <final_answer> objective </final_answer>\n\nInput: she also has an ulcer and does n't get much sleep .\nOutput: <final_answer>objective</final_answer>\n\nInput: this bold and cathartic drama deserves to be experienced by those who cherish intimate dramas about individuals struggling against all odds to practice love , compassion , and forgiveness .\nOutput: <final_answer> subjective </final_answer>\n\nInput: "
        ],
        [
         "12",
         "2",
         "2025-03-13 18:04:06.732074",
         "1627",
         "880",
         "568037",
         "140056",
         "238.084428",
         "0.6632975719932239",
         "You are tasked with analyzing each sentence to determine whether it contains objective information (facts, measurable data) or subjective content (opinions, judgments, emotions). Read the sentence and classify it as either 'subjective' (containing opinions, judgments, or emotions) or 'objective' (presenting verifiable facts without personal bias). Your answer should be formatted as: <final_answer>your classification</final_answer>.\n\nInput: it 's a race against the clock as jay must convince kay -- who not only has no memory of his time spent with the agency , but is also the only person alive who has the expertise to save the galaxy -- to reunite with the mib before earth is destroyed completely .\nOutput: <final_answer> objective </final_answer>\n\nInput: this harrowing journey into combat hell vividly captures the chaotic insanity and personal tragedies that are all too abundant when human hatred spews forth unchecked .\nOutput: <final_answer>subjective</final_answer>\n\nInput: beers , who , when she 's given the right lines , can charm the paint off the wall . . . [ but ] the script goes wrong at several key junctures .\nOutput: <final_answer> subjective </final_answer>\n\nInput: "
        ],
        [
         "13",
         "2",
         "2025-03-13 18:04:06.732074",
         "1627",
         "880",
         "568037",
         "140056",
         "238.084428",
         "0.6629681912290608",
         "Task: Analyze the given sentence to determine whether it is subjective or objective. Subjective sentences contain opinions, judgments, or emotions, while objective sentences present verifiable facts without personal bias. Determine if the sentence conveves factual information (objective) or personal opinions/feelings (subjective). Format your answer as <final_answer>objective</final_answer> or <final_answer>subjective</final_answer>.\n\n\n\nInput: "
        ],
        [
         "14",
         "2",
         "2025-03-13 18:04:06.732074",
         "1627",
         "880",
         "568037",
         "140056",
         "238.084428",
         "0.657312252964427",
         "Subjectivity analysis task: Examine the sentence and determine if it conveys factual information (objective) or personal opinions/feelings (subjective). Format your answer as <final_answer>objective</final_answer> or <final_answer>subjective</final_answer>.\n\nInput: as fran 's requests become more peculiar , chep is thrown into increasingly bizarre situations .\nOutput: <final_answer> objective </final_answer>\n\nInput: . . . comes alive only when it switches gears to the sentimental .\nOutput: <final_answer> subjective </final_answer>\n\nInput: entwined with maggie 's search for hope , the film explores her interaction with her family and friends .\nOutput: To determine whether the sentence conveates factual information or personal opinions/feellings, we need to analyze the content.\n\nThe sentence describes a film that explores a character's interactions with her family and friends. This description is factual and objective, as it describes events and relationships without expressing personal opinions or feelings.\n\n<final_answer>objective</final_answer>\n\nInput: "
        ],
        [
         "15",
         "2",
         "2025-03-13 18:04:06.732074",
         "1627",
         "880",
         "568037",
         "140056",
         "238.084428",
         "0.6452004517221908",
         "Classify as objective (fact-based) or subjective (opinion-based). Answer within <final_answer> </final_answer>.\n\nInput: thekids will probably stay amused at the kaleidoscope of big , colorful characters . mom and dad can catch some quality naptime along the way .\nOutput: <final_answer> subjective </final_answer>\n\nInput: suffers from the lack of a compelling or comprehensible narrative . still , as a visual treat , the film is almost unsurpassed .\nOutput: <final_answer> subjective </final_answer>\n\nInput: after a dream of a horrific car crash , kimberly helps save several people and causes another rift in death 's design , but this time its different , since alex walked off the plane death 's design did not only affect the survivors of flight 180 , but every single person they 've come in contact with , now how will they stop it ?\nOutput: <final_answer> objective </final_answer>\n\nInput: "
        ],
        [
         "16",
         "2",
         "2025-03-13 18:04:06.732074",
         "1627",
         "880",
         "568037",
         "140056",
         "238.084428",
         "0.6306606437041221",
         "You are assigned to evaluate each sentence to ascertain whether it contains objective information (facts, measurable data) or subjective content (opinions, judgments, emotions). Utilizing your knowledge of subjectivity versus objectivity in language, determine if the given sentence is objective (providing facts, information without personal bias) or subjective (expressing opinions, emotions, or personal judgments). Read the sentence and classify it as either 'subjective' (containing opinions, judgments, or emotions) or 'objective' (presenting verifiable facts without personal bias). Your answer should be formatted as: <final_answer>your classification</final_answer>.\n\n\n\nInput: "
        ],
        [
         "17",
         "2",
         "2025-03-13 18:04:06.732074",
         "1627",
         "880",
         "568037",
         "140056",
         "238.084428",
         "0.6252493882928667",
         "Determine whether each sentence is subjective or objective. Analyze the language to decide if the sentence is objective (factual, unbiased, verifiable) or subjective (opinion-based, includes judgments, emotions, or personal perspective). Provide your one-word answer within <final_answer> </final_answer>.\n\n\n\nInput: "
        ],
        [
         "18",
         "2",
         "2025-03-13 18:04:06.732074",
         "1627",
         "880",
         "568037",
         "140056",
         "238.084428",
         "0.6218708827404479",
         "Read the following sentence and classify it as either 'subjective' (containing opinions, judgments, or emotions) or 'objective' (presenting verifiable facts without personal bias). Your answer must be formatted as: <final_answer>your classification</final_answer>\n\n\n\nInput: "
        ],
        [
         "19",
         "2",
         "2025-03-13 18:04:06.732074",
         "1627",
         "880",
         "568037",
         "140056",
         "238.084428",
         "0.6178524374176547",
         "Analyze the given sentence to determine whether it presents an objective statement (factual, unbiased information that can be verified) or a subjective statement (personal opinions, judgments, or emotions that may vary from person to person). Identify whether the sentence conveates facts (objective) or expresses opinions/feelings (subjective). Provide your answer using the format <final_answer>your_answer</final_answer>.\n\nInput: a documentary seven years in the making about women in the film business and how they balance , children , love lives and career -- or how they do n't .\nOutput: <final_answer> objective </final_answer>\n\nInput: ronnie schwann , a young man regarded as `` slow , `` has affections for sarah , a young woman who stays at hope house , a facility for the mentally ill .\nOutput: <final_answer>objective</final_answer>\n\nInput: well , jason 's gone to manhattan and hell , i guess a space station in the year 2455 can be crossed off the list of ideas for the inevitable future sequels ( hey , do n't shoot the messenger ) .\nOutput: <final_answer> subjective </final_answer>\n\nInput: "
        ],
        [
         "20",
         "3",
         "2025-03-13 18:05:07.500832",
         "1814",
         "955",
         "100754",
         "41299",
         "60.767496",
         "0.7378458498023716",
         "Linguistic analysis: Examine the provided sentence and determine whether it's objective (factual, unbiased, could be verified) or subjective (opinion-based, contains judgments, emotions, or personal perspective). Your response should be formatted as <final_answer>objective</final_answer> or <final_answer>subjective</final_answer>.\n\nInput: years of guilt and sorrow tumble over each other as vince struggles to retain his sanity and understand who it is he is hoping to find alive .\nOutput: <final_answer> objective </final_answer>\n\nInput: she also has an ulcer and does n't get much sleep .\nOutput: <final_answer>objective</final_answer>\n\nInput: this bold and cathartic drama deserves to be experienced by those who cherish intimate dramas about individuals struggling against all odds to practice love , compassion , and forgiveness .\nOutput: <final_answer> subjective </final_answer>\n\nInput: "
        ],
        [
         "21",
         "3",
         "2025-03-13 18:05:07.500832",
         "1814",
         "955",
         "100754",
         "41299",
         "60.767496",
         "0.707345191040843",
         "You are tasked with analyzing each sentence to determine whether it contains objective information (facts, measurable data) or subjective content (opinions, judgments, emotions). Read the sentence and classify it as either 'subjective' (containing opinions, judgments, or emotions) or 'objective' (presenting verifiable facts without personal bias). Your answer should be formatted as: <final_answer>your classification</final_answer>.\n\nInput: it 's a race against the clock as jay must convince kay -- who not only has no memory of his time spent with the agency , but is also the only person alive who has the expertise to save the galaxy -- to reunite with the mib before earth is destroyed completely .\nOutput: <final_answer> objective </final_answer>\n\nInput: this harrowing journey into combat hell vividly captures the chaotic insanity and personal tragedies that are all too abundant when human hatred spews forth unchecked .\nOutput: <final_answer>subjective</final_answer>\n\nInput: beers , who , when she 's given the right lines , can charm the paint off the wall . . . [ but ] the script goes wrong at several key junctures .\nOutput: <final_answer> subjective </final_answer>\n\nInput: "
        ],
        [
         "22",
         "3",
         "2025-03-13 18:05:07.500832",
         "1814",
         "955",
         "100754",
         "41299",
         "60.767496",
         "0.6954216073781292",
         "Task: Classify each sentence as either subjective or objective. Determine whether the sentence presents factual, verifiable information (objective) or expresses personal viewpoints, feelings, or judgments (subjective). Provide your answer in the format <final_answer>your_answer</final_answer>.\n\nInput: after a dream of a horrific car crash , kimberly helps save several people and causes another rift in death 's design , but this time its different , since alex walked off the plane death 's design did not only affect the survivors of flight 180 , but every single person they 've come in contact with , now how will they stop it ?\nOutput: <final_answer> objective </final_answer>\n\nInput: steve 's best friend , sean , on the other hand , has n't been so lucky .\nOutput: <final_answer> objective </final_answer>\n\nInput: completely creatively stillborn and executed in a manner that i 'm not sure could be a single iota worse . . . a soulless hunk of exploitative garbage .\nOutput: <final_answer> subjective </final_answer>\n\nInput: "
        ],
        [
         "23",
         "3",
         "2025-03-13 18:05:07.500832",
         "1814",
         "955",
         "100754",
         "41299",
         "60.767496",
         "0.6820158102766799",
         "Task: Analyze the given sentence to determine whether it is subjective or objective. Subjective sentences contain opinions, judgments, or emotions, while objective sentences present verifiable facts without personal bias. Determine if the sentence conveves factual information (objective) or personal opinions/feelings (subjective). Format your answer as <final_answer>objective</final_answer> or <final_answer>subjective</final_answer>.\n\n\n\nInput: "
        ],
        [
         "24",
         "3",
         "2025-03-13 18:05:07.500832",
         "1814",
         "955",
         "100754",
         "41299",
         "60.767496",
         "0.6788208168642953",
         "Determine whether each sentence is subjective or objective. Analyze the language to decide if the sentence is objective (factual, unbiased, verifiable) or subjective (opinion-based, includes judgments, emotions, or personal perspective). Provide your one-word answer within <final_answer> </final_answer>.\n\n\n\nInput: "
        ],
        [
         "25",
         "3",
         "2025-03-13 18:05:07.500832",
         "1814",
         "955",
         "100754",
         "41299",
         "60.767496",
         "0.6761528326745716",
         "Classify as objective (fact-based) or subjective (opinion-based). Answer within <final_answer> </final_answer>.\n\nInput: thekids will probably stay amused at the kaleidoscope of big , colorful characters . mom and dad can catch some quality naptime along the way .\nOutput: <final_answer> subjective </final_answer>\n\nInput: suffers from the lack of a compelling or comprehensible narrative . still , as a visual treat , the film is almost unsurpassed .\nOutput: <final_answer> subjective </final_answer>\n\nInput: after a dream of a horrific car crash , kimberly helps save several people and causes another rift in death 's design , but this time its different , since alex walked off the plane death 's design did not only affect the survivors of flight 180 , but every single person they 've come in contact with , now how will they stop it ?\nOutput: <final_answer> objective </final_answer>\n\nInput: "
        ],
        [
         "26",
         "3",
         "2025-03-13 18:05:07.500832",
         "1814",
         "955",
         "100754",
         "41299",
         "60.767496",
         "0.667852437417655",
         "Analyze the given sentence to determine whether it presents an objective statement (factual, unbiased information that can be verified) or a subjective statement (personal opinions, judgments, or emotions that may vary from person to person). Identify whether the sentence conveates facts (objective) or expresses opinions/feelings (subjective). Provide your answer using the format <final_answer>your_answer</final_answer>.\n\nInput: a documentary seven years in the making about women in the film business and how they balance , children , love lives and career -- or how they do n't .\nOutput: <final_answer> objective </final_answer>\n\nInput: ronnie schwann , a young man regarded as `` slow , `` has affections for sarah , a young woman who stays at hope house , a facility for the mentally ill .\nOutput: <final_answer>objective</final_answer>\n\nInput: well , jason 's gone to manhattan and hell , i guess a space station in the year 2455 can be crossed off the list of ideas for the inevitable future sequels ( hey , do n't shoot the messenger ) .\nOutput: <final_answer> subjective </final_answer>\n\nInput: "
        ],
        [
         "27",
         "3",
         "2025-03-13 18:05:07.500832",
         "1814",
         "955",
         "100754",
         "41299",
         "60.767496",
         "0.6656455862977602",
         "Subjectivity analysis task: Examine the sentence and determine if it conveys factual information (objective) or personal opinions/feelings (subjective). Format your answer as <final_answer>objective</final_answer> or <final_answer>subjective</final_answer>.\n\nInput: as fran 's requests become more peculiar , chep is thrown into increasingly bizarre situations .\nOutput: <final_answer> objective </final_answer>\n\nInput: . . . comes alive only when it switches gears to the sentimental .\nOutput: <final_answer> subjective </final_answer>\n\nInput: entwined with maggie 's search for hope , the film explores her interaction with her family and friends .\nOutput: To determine whether the sentence conveates factual information or personal opinions/feellings, we need to analyze the content.\n\nThe sentence describes a film that explores a character's interactions with her family and friends. This description is factual and objective, as it describes events and relationships without expressing personal opinions or feelings.\n\n<final_answer>objective</final_answer>\n\nInput: "
        ],
        [
         "28",
         "3",
         "2025-03-13 18:05:07.500832",
         "1814",
         "955",
         "100754",
         "41299",
         "60.767496",
         "0.6635375494071146",
         "Read the following sentence and classify it as either 'subjective' (containing opinions, judgments, or emotions) or 'objective' (presenting verifiable facts without personal bias). Your answer must be formatted as: <final_answer>your classification</final_answer>\n\n\n\nInput: "
        ],
        [
         "29",
         "3",
         "2025-03-13 18:05:07.500832",
         "1814",
         "955",
         "100754",
         "41299",
         "60.767496",
         "0.6568511198945984",
         "You are assigned to evaluate each sentence to ascertain whether it contains objective information (facts, measurable data) or subjective content (opinions, judgments, emotions). Utilizing your knowledge of subjectivity versus objectivity in language, determine if the given sentence is objective (providing facts, information without personal bias) or subjective (expressing opinions, emotions, or personal judgments). Read the sentence and classify it as either 'subjective' (containing opinions, judgments, or emotions) or 'objective' (presenting verifiable facts without personal bias). Your answer should be formatted as: <final_answer>your classification</final_answer>.\n\n\n\nInput: "
        ],
        [
         "30",
         "4",
         "2025-03-13 18:06:17.943019",
         "1775",
         "916",
         "130451",
         "43164",
         "70.440861",
         "0.7161791831357048",
         "Linguistic analysis: Examine the provided sentence and determine whether it's objective (factual, unbiased, could be verified) or subjective (opinion-based, contains judgments, emotions, or personal perspective). Your response should be formatted as <final_answer>objective</final_answer> or <final_answer>subjective</final_answer>.\n\nInput: years of guilt and sorrow tumble over each other as vince struggles to retain his sanity and understand who it is he is hoping to find alive .\nOutput: <final_answer> objective </final_answer>\n\nInput: she also has an ulcer and does n't get much sleep .\nOutput: <final_answer>objective</final_answer>\n\nInput: this bold and cathartic drama deserves to be experienced by those who cherish intimate dramas about individuals struggling against all odds to practice love , compassion , and forgiveness .\nOutput: <final_answer> subjective </final_answer>\n\nInput: "
        ],
        [
         "31",
         "4",
         "2025-03-13 18:06:17.943019",
         "1775",
         "916",
         "130451",
         "43164",
         "70.440861",
         "0.7037549407114625",
         "Task: Classify each sentence as either subjective or objective. Determine whether the sentence presents factual, verifiable information (objective) or expresses personal viewpoints, feelings, or judgments (subjective). Provide your answer in the format <final_answer>your_answer</final_answer>.\n\nInput: after a dream of a horrific car crash , kimberly helps save several people and causes another rift in death 's design , but this time its different , since alex walked off the plane death 's design did not only affect the survivors of flight 180 , but every single person they 've come in contact with , now how will they stop it ?\nOutput: <final_answer> objective </final_answer>\n\nInput: steve 's best friend , sean , on the other hand , has n't been so lucky .\nOutput: <final_answer> objective </final_answer>\n\nInput: completely creatively stillborn and executed in a manner that i 'm not sure could be a single iota worse . . . a soulless hunk of exploitative garbage .\nOutput: <final_answer> subjective </final_answer>\n\nInput: "
        ],
        [
         "32",
         "4",
         "2025-03-13 18:06:17.943019",
         "1775",
         "916",
         "130451",
         "43164",
         "70.440861",
         "0.6823451910408431",
         "You are tasked with analyzing each sentence to determine whether it contains objective information (facts, measurable data) or subjective content (opinions, judgments, emotions). Read the sentence and classify it as either 'subjective' (containing opinions, judgments, or emotions) or 'objective' (presenting verifiable facts without personal bias). Your answer should be formatted as: <final_answer>your classification</final_answer>.\n\nInput: it 's a race against the clock as jay must convince kay -- who not only has no memory of his time spent with the agency , but is also the only person alive who has the expertise to save the galaxy -- to reunite with the mib before earth is destroyed completely .\nOutput: <final_answer> objective </final_answer>\n\nInput: this harrowing journey into combat hell vividly captures the chaotic insanity and personal tragedies that are all too abundant when human hatred spews forth unchecked .\nOutput: <final_answer>subjective</final_answer>\n\nInput: beers , who , when she 's given the right lines , can charm the paint off the wall . . . [ but ] the script goes wrong at several key junctures .\nOutput: <final_answer> subjective </final_answer>\n\nInput: "
        ],
        [
         "33",
         "4",
         "2025-03-13 18:06:17.943019",
         "1775",
         "916",
         "130451",
         "43164",
         "70.440861",
         "0.6730961791831356",
         "Task: Examine the provided sentence to ascertain whether it is subjective or objective. Subjective sentences include opinions, judgments, and emotions, while objective sentences present verifiable facts without personal bias. Determine if the sentence conveves factual information (objective) or personal opinions/feelings (subjective). Analyze the language to decide if the sentence is objective (factual, unbiased, verifiable) or subjective (opinion-based, includes judgments, emotions, or personal perspective). Provide your one-word answer within <final_answer> </final_answer>.\n\nInput: at the end of the worst day of his life , bruce angrily ridicules and rages against god and god responds .\nOutput: <final_answer> objective </final_answer>\n\nInput: "
        ],
        [
         "34",
         "4",
         "2025-03-13 18:06:17.943019",
         "1775",
         "916",
         "130451",
         "43164",
         "70.440861",
         "0.6720158102766798",
         "Task: Analyze the given sentence to determine whether it is subjective or objective. Subjective sentences contain opinions, judgments, or emotions, while objective sentences present verifiable facts without personal bias. Determine if the sentence conveves factual information (objective) or personal opinions/feelings (subjective). Format your answer as <final_answer>objective</final_answer> or <final_answer>subjective</final_answer>.\n\n\n\nInput: "
        ],
        [
         "35",
         "4",
         "2025-03-13 18:06:17.943019",
         "1775",
         "916",
         "130451",
         "43164",
         "70.440861",
         "0.6706455862977603",
         "Subjectivity analysis task: Examine the sentence and determine if it conveys factual information (objective) or personal opinions/feelings (subjective). Format your answer as <final_answer>objective</final_answer> or <final_answer>subjective</final_answer>.\n\nInput: as fran 's requests become more peculiar , chep is thrown into increasingly bizarre situations .\nOutput: <final_answer> objective </final_answer>\n\nInput: . . . comes alive only when it switches gears to the sentimental .\nOutput: <final_answer> subjective </final_answer>\n\nInput: entwined with maggie 's search for hope , the film explores her interaction with her family and friends .\nOutput: To determine whether the sentence conveates factual information or personal opinions/feellings, we need to analyze the content.\n\nThe sentence describes a film that explores a character's interactions with her family and friends. This description is factual and objective, as it describes events and relationships without expressing personal opinions or feelings.\n\n<final_answer>objective</final_answer>\n\nInput: "
        ],
        [
         "36",
         "4",
         "2025-03-13 18:06:17.943019",
         "1775",
         "916",
         "130451",
         "43164",
         "70.440861",
         "0.6594861660079052",
         "Classify as objective (fact-based) or subjective (opinion-based). Answer within <final_answer> </final_answer>.\n\nInput: thekids will probably stay amused at the kaleidoscope of big , colorful characters . mom and dad can catch some quality naptime along the way .\nOutput: <final_answer> subjective </final_answer>\n\nInput: suffers from the lack of a compelling or comprehensible narrative . still , as a visual treat , the film is almost unsurpassed .\nOutput: <final_answer> subjective </final_answer>\n\nInput: after a dream of a horrific car crash , kimberly helps save several people and causes another rift in death 's design , but this time its different , since alex walked off the plane death 's design did not only affect the survivors of flight 180 , but every single person they 've come in contact with , now how will they stop it ?\nOutput: <final_answer> objective </final_answer>\n\nInput: "
        ],
        [
         "37",
         "4",
         "2025-03-13 18:06:17.943019",
         "1775",
         "916",
         "130451",
         "43164",
         "70.440861",
         "0.6438208168642952",
         "Determine whether each sentence is subjective or objective. Analyze the language to decide if the sentence is objective (factual, unbiased, verifiable) or subjective (opinion-based, includes judgments, emotions, or personal perspective). Provide your one-word answer within <final_answer> </final_answer>.\n\n\n\nInput: "
        ],
        [
         "38",
         "4",
         "2025-03-13 18:06:17.943019",
         "1775",
         "916",
         "130451",
         "43164",
         "70.440861",
         "0.6345191040843214",
         "Analyze the given sentence to determine whether it presents an objective statement (factual, unbiased information that can be verified) or a subjective statement (personal opinions, judgments, or emotions that may vary from person to person). Identify whether the sentence conveates facts (objective) or expresses opinions/feelings (subjective). Provide your answer using the format <final_answer>your_answer</final_answer>.\n\nInput: a documentary seven years in the making about women in the film business and how they balance , children , love lives and career -- or how they do n't .\nOutput: <final_answer> objective </final_answer>\n\nInput: ronnie schwann , a young man regarded as `` slow , `` has affections for sarah , a young woman who stays at hope house , a facility for the mentally ill .\nOutput: <final_answer>objective</final_answer>\n\nInput: well , jason 's gone to manhattan and hell , i guess a space station in the year 2455 can be crossed off the list of ideas for the inevitable future sequels ( hey , do n't shoot the messenger ) .\nOutput: <final_answer> subjective </final_answer>\n\nInput: "
        ],
        [
         "39",
         "4",
         "2025-03-13 18:06:17.943019",
         "1775",
         "916",
         "130451",
         "43164",
         "70.440861",
         "0.633517786561265",
         "You are assigned to evaluate each sentence to ascertain whether it contains objective information (facts, measurable data) or subjective content (opinions, judgments, emotions). Utilizing your knowledge of subjectivity versus objectivity in language, determine if the given sentence is objective (providing facts, information without personal bias) or subjective (expressing opinions, emotions, or personal judgments). Read the sentence and classify it as either 'subjective' (containing opinions, judgments, or emotions) or 'objective' (presenting verifiable facts without personal bias). Your answer should be formatted as: <final_answer>your classification</final_answer>.\n\n\n\nInput: "
        ],
        [
         "40",
         "5",
         "2025-03-13 18:07:54.794363",
         "1701",
         "911",
         "160556",
         "64794",
         "96.849998",
         "0.7146977016542234",
         "Linguistic analysis: Examine the provided sentence and determine whether it's objective (factual, unbiased, could be verified) or subjective (opinion-based, contains judgments, emotions, or personal perspective). Your response should be formatted as <final_answer>objective</final_answer> or <final_answer>subjective</final_answer>.\n\nInput: years of guilt and sorrow tumble over each other as vince struggles to retain his sanity and understand who it is he is hoping to find alive .\nOutput: <final_answer> objective </final_answer>\n\nInput: she also has an ulcer and does n't get much sleep .\nOutput: <final_answer>objective</final_answer>\n\nInput: this bold and cathartic drama deserves to be experienced by those who cherish intimate dramas about individuals struggling against all odds to practice love , compassion , and forgiveness .\nOutput: <final_answer> subjective </final_answer>\n\nInput: "
        ],
        [
         "41",
         "5",
         "2025-03-13 18:07:54.794363",
         "1701",
         "911",
         "160556",
         "64794",
         "96.849998",
         "0.7056067925633144",
         "Task: Classify each sentence as either subjective or objective. Determine whether the sentence presents factual, verifiable information (objective) or expresses personal viewpoints, feelings, or judgments (subjective). Provide your answer in the format <final_answer>your_answer</final_answer>.\n\nInput: after a dream of a horrific car crash , kimberly helps save several people and causes another rift in death 's design , but this time its different , since alex walked off the plane death 's design did not only affect the survivors of flight 180 , but every single person they 've come in contact with , now how will they stop it ?\nOutput: <final_answer> objective </final_answer>\n\nInput: steve 's best friend , sean , on the other hand , has n't been so lucky .\nOutput: <final_answer> objective </final_answer>\n\nInput: completely creatively stillborn and executed in a manner that i 'm not sure could be a single iota worse . . . a soulless hunk of exploitative garbage .\nOutput: <final_answer> subjective </final_answer>\n\nInput: "
        ],
        [
         "42",
         "5",
         "2025-03-13 18:07:54.794363",
         "1701",
         "911",
         "160556",
         "64794",
         "96.849998",
         "0.6919850680720243",
         "Task: Examine the provided sentence to ascertain whether it is subjective or objective. Subjective sentences include opinions, judgments, and emotions, while objective sentences present verifiable facts without personal bias. Determine if the sentence conveves factual information (objective) or personal opinions/feelings (subjective). Analyze the language to decide if the sentence is objective (factual, unbiased, verifiable) or subjective (opinion-based, includes judgments, emotions, or personal perspective). Provide your one-word answer within <final_answer> </final_answer>.\n\nInput: at the end of the worst day of his life , bruce angrily ridicules and rages against god and god responds .\nOutput: <final_answer> objective </final_answer>\n\nInput: "
        ],
        [
         "43",
         "5",
         "2025-03-13 18:07:54.794363",
         "1701",
         "911",
         "160556",
         "64794",
         "96.849998",
         "0.6786414873371395",
         "You are tasked with analyzing each sentence to determine whether it contains objective information (facts, measurable data) or subjective content (opinions, judgments, emotions). Read the sentence and classify it as either 'subjective' (containing opinions, judgments, or emotions) or 'objective' (presenting verifiable facts without personal bias). Your answer should be formatted as: <final_answer>your classification</final_answer>.\n\nInput: it 's a race against the clock as jay must convince kay -- who not only has no memory of his time spent with the agency , but is also the only person alive who has the expertise to save the galaxy -- to reunite with the mib before earth is destroyed completely .\nOutput: <final_answer> objective </final_answer>\n\nInput: this harrowing journey into combat hell vividly captures the chaotic insanity and personal tragedies that are all too abundant when human hatred spews forth unchecked .\nOutput: <final_answer>subjective</final_answer>\n\nInput: beers , who , when she 's given the right lines , can charm the paint off the wall . . . [ but ] the script goes wrong at several key junctures .\nOutput: <final_answer> subjective </final_answer>\n\nInput: "
        ],
        [
         "44",
         "5",
         "2025-03-13 18:07:54.794363",
         "1701",
         "911",
         "160556",
         "64794",
         "96.849998",
         "0.6758307714829453",
         "Subjectivity analysis task: Examine the sentence and determine if it conveys factual information (objective) or personal opinions/feelings (subjective). Format your answer as <final_answer>objective</final_answer> or <final_answer>subjective</final_answer>.\n\nInput: as fran 's requests become more peculiar , chep is thrown into increasingly bizarre situations .\nOutput: <final_answer> objective </final_answer>\n\nInput: . . . comes alive only when it switches gears to the sentimental .\nOutput: <final_answer> subjective </final_answer>\n\nInput: entwined with maggie 's search for hope , the film explores her interaction with her family and friends .\nOutput: To determine whether the sentence conveates factual information or personal opinions/feellings, we need to analyze the content.\n\nThe sentence describes a film that explores a character's interactions with her family and friends. This description is factual and objective, as it describes events and relationships without expressing personal opinions or feelings.\n\n<final_answer>objective</final_answer>\n\nInput: "
        ],
        [
         "45",
         "5",
         "2025-03-13 18:07:54.794363",
         "1701",
         "911",
         "160556",
         "64794",
         "96.849998",
         "0.6746084028692725",
         "Task: Analyze the given sentence to determine whether it is subjective or objective. Subjective sentences contain opinions, judgments, or emotions, while objective sentences present verifiable facts without personal bias. Determine if the sentence conveves factual information (objective) or personal opinions/feelings (subjective). Format your answer as <final_answer>objective</final_answer> or <final_answer>subjective</final_answer>.\n\n\n\nInput: "
        ],
        [
         "46",
         "5",
         "2025-03-13 18:07:54.794363",
         "1701",
         "911",
         "160556",
         "64794",
         "96.849998",
         "0.6557824623042013",
         "Classify as objective (fact-based) or subjective (opinion-based). Answer within <final_answer> </final_answer>.\n\nInput: thekids will probably stay amused at the kaleidoscope of big , colorful characters . mom and dad can catch some quality naptime along the way .\nOutput: <final_answer> subjective </final_answer>\n\nInput: suffers from the lack of a compelling or comprehensible narrative . still , as a visual treat , the film is almost unsurpassed .\nOutput: <final_answer> subjective </final_answer>\n\nInput: after a dream of a horrific car crash , kimberly helps save several people and causes another rift in death 's design , but this time its different , since alex walked off the plane death 's design did not only affect the survivors of flight 180 , but every single person they 've come in contact with , now how will they stop it ?\nOutput: <final_answer> objective </final_answer>\n\nInput: "
        ],
        [
         "47",
         "5",
         "2025-03-13 18:07:54.794363",
         "1701",
         "911",
         "160556",
         "64794",
         "96.849998",
         "0.6464134094568877",
         "Determine whether each sentence is subjective or objective. Analyze the language to decide if the sentence is objective (factual, unbiased, verifiable) or subjective (opinion-based, includes judgments, emotions, or personal perspective). Provide your one-word answer within <final_answer> </final_answer>.\n\n\n\nInput: "
        ],
        [
         "48",
         "5",
         "2025-03-13 18:07:54.794363",
         "1701",
         "911",
         "160556",
         "64794",
         "96.849998",
         "0.6400746596398771",
         "Analyze the given sentence to determine whether it presents an objective statement (factual, unbiased information that can be verified) or a subjective statement (personal opinions, judgments, or emotions that may vary from person to person). Identify whether the sentence conveates facts (objective) or expresses opinions/feelings (subjective). Provide your answer using the format <final_answer>your_answer</final_answer>.\n\nInput: a documentary seven years in the making about women in the film business and how they balance , children , love lives and career -- or how they do n't .\nOutput: <final_answer> objective </final_answer>\n\nInput: ronnie schwann , a young man regarded as `` slow , `` has affections for sarah , a young woman who stays at hope house , a facility for the mentally ill .\nOutput: <final_answer>objective</final_answer>\n\nInput: well , jason 's gone to manhattan and hell , i guess a space station in the year 2455 can be crossed off the list of ideas for the inevitable future sequels ( hey , do n't shoot the messenger ) .\nOutput: <final_answer> subjective </final_answer>\n\nInput: "
        ],
        [
         "49",
         "5",
         "2025-03-13 18:07:54.794363",
         "1701",
         "911",
         "160556",
         "64794",
         "96.849998",
         "0.636480749524228",
         "You are assigned to evaluate each sentence to ascertain whether it contains objective information (facts, measurable data) or subjective content (opinions, judgments, emotions). Utilizing your knowledge of subjectivity versus objectivity in language, determine if the given sentence is objective (providing facts, information without personal bias) or subjective (expressing opinions, emotions, or personal judgments). Read the sentence and classify it as either 'subjective' (containing opinions, judgments, or emotions) or 'objective' (presenting verifiable facts without personal bias). Your answer should be formatted as: <final_answer>your classification</final_answer>.\n\n\n\nInput: "
        ]
       ],
       "shape": {
        "columns": 9,
        "rows": 220
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>step</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>input_tokens_meta_llm</th>\n",
       "      <th>output_tokens_meta_llm</th>\n",
       "      <th>input_tokens_downstream_llm</th>\n",
       "      <th>output_tokens_downstream_llm</th>\n",
       "      <th>time_elapsed</th>\n",
       "      <th>score</th>\n",
       "      <th>prompt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2025-03-13 18:00:08.645871</td>\n",
       "      <td>1424</td>\n",
       "      <td>635</td>\n",
       "      <td>161831</td>\n",
       "      <td>29141</td>\n",
       "      <td>125.999972</td>\n",
       "      <td>0.762846</td>\n",
       "      <td>Linguistic analysis: Examine the provided sent...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2025-03-13 18:00:08.645871</td>\n",
       "      <td>1424</td>\n",
       "      <td>635</td>\n",
       "      <td>161831</td>\n",
       "      <td>29141</td>\n",
       "      <td>125.999972</td>\n",
       "      <td>0.732345</td>\n",
       "      <td>You are tasked with analyzing each sentence to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2025-03-13 18:00:08.645871</td>\n",
       "      <td>1424</td>\n",
       "      <td>635</td>\n",
       "      <td>161831</td>\n",
       "      <td>29141</td>\n",
       "      <td>125.999972</td>\n",
       "      <td>0.720422</td>\n",
       "      <td>Task: Classify each sentence as either subject...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2025-03-13 18:00:08.645871</td>\n",
       "      <td>1424</td>\n",
       "      <td>635</td>\n",
       "      <td>161831</td>\n",
       "      <td>29141</td>\n",
       "      <td>125.999972</td>\n",
       "      <td>0.676153</td>\n",
       "      <td>Classify as objective (fact-based) or subjecti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2025-03-13 18:00:08.645871</td>\n",
       "      <td>1424</td>\n",
       "      <td>635</td>\n",
       "      <td>161831</td>\n",
       "      <td>29141</td>\n",
       "      <td>125.999972</td>\n",
       "      <td>0.657312</td>\n",
       "      <td>Subjectivity analysis task: Examine the senten...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>22</td>\n",
       "      <td>2025-03-13 18:28:36.638667</td>\n",
       "      <td>2085</td>\n",
       "      <td>1154</td>\n",
       "      <td>115851</td>\n",
       "      <td>39132</td>\n",
       "      <td>77.708483</td>\n",
       "      <td>0.697704</td>\n",
       "      <td>Task: Analyze the sentence to determine whethe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>22</td>\n",
       "      <td>2025-03-13 18:28:36.638667</td>\n",
       "      <td>2085</td>\n",
       "      <td>1154</td>\n",
       "      <td>115851</td>\n",
       "      <td>39132</td>\n",
       "      <td>77.708483</td>\n",
       "      <td>0.691850</td>\n",
       "      <td>Task: Classify each sentence as either subject...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>22</td>\n",
       "      <td>2025-03-13 18:28:36.638667</td>\n",
       "      <td>2085</td>\n",
       "      <td>1154</td>\n",
       "      <td>115851</td>\n",
       "      <td>39132</td>\n",
       "      <td>77.708483</td>\n",
       "      <td>0.684237</td>\n",
       "      <td>Task: Analyze the sentence to determine whethe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>22</td>\n",
       "      <td>2025-03-13 18:28:36.638667</td>\n",
       "      <td>2085</td>\n",
       "      <td>1154</td>\n",
       "      <td>115851</td>\n",
       "      <td>39132</td>\n",
       "      <td>77.708483</td>\n",
       "      <td>0.658536</td>\n",
       "      <td>You are tasked with analyzing each sentence to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>22</td>\n",
       "      <td>2025-03-13 18:28:36.638667</td>\n",
       "      <td>2085</td>\n",
       "      <td>1154</td>\n",
       "      <td>115851</td>\n",
       "      <td>39132</td>\n",
       "      <td>77.708483</td>\n",
       "      <td>0.658206</td>\n",
       "      <td>Task: Analyze the given sentence to determine ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>220 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     step                   timestamp  input_tokens_meta_llm  \\\n",
       "0       1  2025-03-13 18:00:08.645871                   1424   \n",
       "1       1  2025-03-13 18:00:08.645871                   1424   \n",
       "2       1  2025-03-13 18:00:08.645871                   1424   \n",
       "3       1  2025-03-13 18:00:08.645871                   1424   \n",
       "4       1  2025-03-13 18:00:08.645871                   1424   \n",
       "..    ...                         ...                    ...   \n",
       "215    22  2025-03-13 18:28:36.638667                   2085   \n",
       "216    22  2025-03-13 18:28:36.638667                   2085   \n",
       "217    22  2025-03-13 18:28:36.638667                   2085   \n",
       "218    22  2025-03-13 18:28:36.638667                   2085   \n",
       "219    22  2025-03-13 18:28:36.638667                   2085   \n",
       "\n",
       "     output_tokens_meta_llm  input_tokens_downstream_llm  \\\n",
       "0                       635                       161831   \n",
       "1                       635                       161831   \n",
       "2                       635                       161831   \n",
       "3                       635                       161831   \n",
       "4                       635                       161831   \n",
       "..                      ...                          ...   \n",
       "215                    1154                       115851   \n",
       "216                    1154                       115851   \n",
       "217                    1154                       115851   \n",
       "218                    1154                       115851   \n",
       "219                    1154                       115851   \n",
       "\n",
       "     output_tokens_downstream_llm  time_elapsed     score  \\\n",
       "0                           29141    125.999972  0.762846   \n",
       "1                           29141    125.999972  0.732345   \n",
       "2                           29141    125.999972  0.720422   \n",
       "3                           29141    125.999972  0.676153   \n",
       "4                           29141    125.999972  0.657312   \n",
       "..                            ...           ...       ...   \n",
       "215                         39132     77.708483  0.697704   \n",
       "216                         39132     77.708483  0.691850   \n",
       "217                         39132     77.708483  0.684237   \n",
       "218                         39132     77.708483  0.658536   \n",
       "219                         39132     77.708483  0.658206   \n",
       "\n",
       "                                                prompt  \n",
       "0    Linguistic analysis: Examine the provided sent...  \n",
       "1    You are tasked with analyzing each sentence to...  \n",
       "2    Task: Classify each sentence as either subject...  \n",
       "3    Classify as objective (fact-based) or subjecti...  \n",
       "4    Subjectivity analysis task: Examine the senten...  \n",
       "..                                                 ...  \n",
       "215  Task: Analyze the sentence to determine whethe...  \n",
       "216  Task: Classify each sentence as either subject...  \n",
       "217  Task: Analyze the sentence to determine whethe...  \n",
       "218  You are tasked with analyzing each sentence to...  \n",
       "219  Task: Analyze the given sentence to determine ...  \n",
       "\n",
       "[220 rows x 9 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = r\"C:\\Users\\schla\\git\\capo\\results\\subj\\mistral\\CAPO\\seed42\\benchmark_experiment_subj_mistral_CAPO_42\\eac414135d4beaa2a3c24f16de77a4ba73ef222b9c99448e70552d4574f76b21\\step_results.csv\"\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv(path)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "step",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "timestamp",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "input_tokens_meta_llm",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "output_tokens_meta_llm",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "input_tokens_downstream_llm",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "output_tokens_downstream_llm",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "time_elapsed",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "score",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "prompt",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "8c502e42-5d8a-478d-8390-f7d9bca8968c",
       "rows": [
        [
         "0",
         "1",
         "2025-03-13 18:00:08.645871",
         "1424",
         "635",
         "161831",
         "29141",
         "125.999972",
         "0.7628458498023714",
         "Linguistic analysis: Examine the provided sentence and determine whether it's objective (factual, unbiased, could be verified) or subjective (opinion-based, contains judgments, emotions, or personal perspective). Your response should be formatted as <final_answer>objective</final_answer> or <final_answer>subjective</final_answer>.\n\nInput: years of guilt and sorrow tumble over each other as vince struggles to retain his sanity and understand who it is he is hoping to find alive .\nOutput: <final_answer> objective </final_answer>\n\nInput: she also has an ulcer and does n't get much sleep .\nOutput: <final_answer>objective</final_answer>\n\nInput: this bold and cathartic drama deserves to be experienced by those who cherish intimate dramas about individuals struggling against all odds to practice love , compassion , and forgiveness .\nOutput: <final_answer> subjective </final_answer>\n\nInput: "
        ],
        [
         "1",
         "1",
         "2025-03-13 18:00:08.645871",
         "1424",
         "635",
         "161831",
         "29141",
         "125.999972",
         "0.7323451910408433",
         "You are tasked with analyzing each sentence to determine whether it contains objective information (facts, measurable data) or subjective content (opinions, judgments, emotions). Read the sentence and classify it as either 'subjective' (containing opinions, judgments, or emotions) or 'objective' (presenting verifiable facts without personal bias). Your answer should be formatted as: <final_answer>your classification</final_answer>.\n\nInput: it 's a race against the clock as jay must convince kay -- who not only has no memory of his time spent with the agency , but is also the only person alive who has the expertise to save the galaxy -- to reunite with the mib before earth is destroyed completely .\nOutput: <final_answer> objective </final_answer>\n\nInput: this harrowing journey into combat hell vividly captures the chaotic insanity and personal tragedies that are all too abundant when human hatred spews forth unchecked .\nOutput: <final_answer>subjective</final_answer>\n\nInput: beers , who , when she 's given the right lines , can charm the paint off the wall . . . [ but ] the script goes wrong at several key junctures .\nOutput: <final_answer> subjective </final_answer>\n\nInput: "
        ],
        [
         "2",
         "1",
         "2025-03-13 18:00:08.645871",
         "1424",
         "635",
         "161831",
         "29141",
         "125.999972",
         "0.7204216073781292",
         "Task: Classify each sentence as either subjective or objective. Determine whether the sentence presents factual, verifiable information (objective) or expresses personal viewpoints, feelings, or judgments (subjective). Provide your answer in the format <final_answer>your_answer</final_answer>.\n\nInput: after a dream of a horrific car crash , kimberly helps save several people and causes another rift in death 's design , but this time its different , since alex walked off the plane death 's design did not only affect the survivors of flight 180 , but every single person they 've come in contact with , now how will they stop it ?\nOutput: <final_answer> objective </final_answer>\n\nInput: steve 's best friend , sean , on the other hand , has n't been so lucky .\nOutput: <final_answer> objective </final_answer>\n\nInput: completely creatively stillborn and executed in a manner that i 'm not sure could be a single iota worse . . . a soulless hunk of exploitative garbage .\nOutput: <final_answer> subjective </final_answer>\n\nInput: "
        ],
        [
         "3",
         "1",
         "2025-03-13 18:00:08.645871",
         "1424",
         "635",
         "161831",
         "29141",
         "125.999972",
         "0.6761528326745718",
         "Classify as objective (fact-based) or subjective (opinion-based). Answer within <final_answer> </final_answer>.\n\nInput: thekids will probably stay amused at the kaleidoscope of big , colorful characters . mom and dad can catch some quality naptime along the way .\nOutput: <final_answer> subjective </final_answer>\n\nInput: suffers from the lack of a compelling or comprehensible narrative . still , as a visual treat , the film is almost unsurpassed .\nOutput: <final_answer> subjective </final_answer>\n\nInput: after a dream of a horrific car crash , kimberly helps save several people and causes another rift in death 's design , but this time its different , since alex walked off the plane death 's design did not only affect the survivors of flight 180 , but every single person they 've come in contact with , now how will they stop it ?\nOutput: <final_answer> objective </final_answer>\n\nInput: "
        ],
        [
         "4",
         "1",
         "2025-03-13 18:00:08.645871",
         "1424",
         "635",
         "161831",
         "29141",
         "125.999972",
         "0.6573122529644271",
         "Subjectivity analysis task: Examine the sentence and determine if it conveys factual information (objective) or personal opinions/feelings (subjective). Format your answer as <final_answer>objective</final_answer> or <final_answer>subjective</final_answer>.\n\nInput: as fran 's requests become more peculiar , chep is thrown into increasingly bizarre situations .\nOutput: <final_answer> objective </final_answer>\n\nInput: . . . comes alive only when it switches gears to the sentimental .\nOutput: <final_answer> subjective </final_answer>\n\nInput: entwined with maggie 's search for hope , the film explores her interaction with her family and friends .\nOutput: To determine whether the sentence conveates factual information or personal opinions/feellings, we need to analyze the content.\n\nThe sentence describes a film that explores a character's interactions with her family and friends. This description is factual and objective, as it describes events and relationships without expressing personal opinions or feelings.\n\n<final_answer>objective</final_answer>\n\nInput: "
        ],
        [
         "5",
         "1",
         "2025-03-13 18:00:08.645871",
         "1424",
         "635",
         "161831",
         "29141",
         "125.999972",
         "0.6409749670619237",
         "Sentence classification task: Does the sentence state facts (objective) or express opinions/feelings (subjective)? Provide your answer using the format <final_answer>your_answer</final_answer>.\n\nInput: a movie that will surely be profane , politically charged music to the ears of cho 's fans .\nOutput: <final_answer> subjective </final_answer>\n\nInput: ronnie schwann , a young man regarded as `` slow , `` has affections for sarah , a young woman who stays at hope house , a facility for the mentally ill .\nOutput: <final_answer>objective</final_answer>\n\nInput: "
        ],
        [
         "6",
         "1",
         "2025-03-13 18:00:08.645871",
         "1424",
         "635",
         "161831",
         "29141",
         "125.999972",
         "0.6371541501976281",
         "Determine whether each sentence is subjective or objective. Analyze the language to decide if the sentence is objective (factual, unbiased, verifiable) or subjective (opinion-based, includes judgments, emotions, or personal perspective). Provide your one-word answer within <final_answer> </final_answer>.\n\n\n\nInput: "
        ],
        [
         "7",
         "1",
         "2025-03-13 18:00:08.645871",
         "1424",
         "635",
         "161831",
         "29141",
         "125.999972",
         "0.6345191040843214",
         "Analyze the given sentence to determine whether it presents an objective statement (factual, unbiased information that can be verified) or a subjective statement (personal opinions, judgments, or emotions that may vary from person to person). Identify whether the sentence conveates facts (objective) or expresses opinions/feelings (subjective). Provide your answer using the format <final_answer>your_answer</final_answer>.\n\nInput: a documentary seven years in the making about women in the film business and how they balance , children , love lives and career -- or how they do n't .\nOutput: <final_answer> objective </final_answer>\n\nInput: ronnie schwann , a young man regarded as `` slow , `` has affections for sarah , a young woman who stays at hope house , a facility for the mentally ill .\nOutput: <final_answer>objective</final_answer>\n\nInput: well , jason 's gone to manhattan and hell , i guess a space station in the year 2455 can be crossed off the list of ideas for the inevitable future sequels ( hey , do n't shoot the messenger ) .\nOutput: <final_answer> subjective </final_answer>\n\nInput: "
        ],
        [
         "8",
         "1",
         "2025-03-13 18:00:08.645871",
         "1424",
         "635",
         "161831",
         "29141",
         "125.999972",
         "0.6166666666666669",
         "Using your understanding of subjectivity vs. objectivity in language, determine if the given sentence is objective (states facts, provides information without personal bias) or subjective (expresses opinions, emotions, or personal judgments). Place your classification between the <final_answer> </final_answer> tags.\n\nInput: huh is taken into custody after kang shoots and wounds him at the scene of the crime .\nOutput: <final_answer> objective </final_answer>\n\nInput: the stars may be college kids , but the subject matter is as adult as you can get : the temptations of the flesh are unleashed by a slightly crazed , overtly determined young woman and a one-night swim turns into an ocean of trouble .\nOutput: To determine whether the given sentence is objective or subjective, we need to analyze the content and the tone.\n\nThe sentence describes a scenario involving college students and their experiences, which includes themes of temptation, determination, and trouble. The language used is descriptive and includes emotional and subjective elements such as \"temptations of the flesh,\" \"crazed,\" \"determined,\" and \"ocean of trouble.\" These elements suggest personal judgments and emotions, which are subjective.\n\n<final_answer>subjective</final_answer>\n\nInput: "
        ],
        [
         "9",
         "1",
         "2025-03-13 18:00:08.645871",
         "1424",
         "635",
         "161831",
         "29141",
         "125.999972",
         "0.6052042160737812",
         "Read the following sentence and classify it as either 'subjective' (containing opinions, judgments, or emotions) or 'objective' (presenting verifiable facts without personal bias). Your answer must be formatted as: <final_answer>your classification</final_answer>\n\n\n\nInput: "
        ]
       ],
       "shape": {
        "columns": 9,
        "rows": 10
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>step</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>input_tokens_meta_llm</th>\n",
       "      <th>output_tokens_meta_llm</th>\n",
       "      <th>input_tokens_downstream_llm</th>\n",
       "      <th>output_tokens_downstream_llm</th>\n",
       "      <th>time_elapsed</th>\n",
       "      <th>score</th>\n",
       "      <th>prompt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2025-03-13 18:00:08.645871</td>\n",
       "      <td>1424</td>\n",
       "      <td>635</td>\n",
       "      <td>161831</td>\n",
       "      <td>29141</td>\n",
       "      <td>125.999972</td>\n",
       "      <td>0.762846</td>\n",
       "      <td>Linguistic analysis: Examine the provided sent...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2025-03-13 18:00:08.645871</td>\n",
       "      <td>1424</td>\n",
       "      <td>635</td>\n",
       "      <td>161831</td>\n",
       "      <td>29141</td>\n",
       "      <td>125.999972</td>\n",
       "      <td>0.732345</td>\n",
       "      <td>You are tasked with analyzing each sentence to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2025-03-13 18:00:08.645871</td>\n",
       "      <td>1424</td>\n",
       "      <td>635</td>\n",
       "      <td>161831</td>\n",
       "      <td>29141</td>\n",
       "      <td>125.999972</td>\n",
       "      <td>0.720422</td>\n",
       "      <td>Task: Classify each sentence as either subject...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2025-03-13 18:00:08.645871</td>\n",
       "      <td>1424</td>\n",
       "      <td>635</td>\n",
       "      <td>161831</td>\n",
       "      <td>29141</td>\n",
       "      <td>125.999972</td>\n",
       "      <td>0.676153</td>\n",
       "      <td>Classify as objective (fact-based) or subjecti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2025-03-13 18:00:08.645871</td>\n",
       "      <td>1424</td>\n",
       "      <td>635</td>\n",
       "      <td>161831</td>\n",
       "      <td>29141</td>\n",
       "      <td>125.999972</td>\n",
       "      <td>0.657312</td>\n",
       "      <td>Subjectivity analysis task: Examine the senten...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>2025-03-13 18:00:08.645871</td>\n",
       "      <td>1424</td>\n",
       "      <td>635</td>\n",
       "      <td>161831</td>\n",
       "      <td>29141</td>\n",
       "      <td>125.999972</td>\n",
       "      <td>0.640975</td>\n",
       "      <td>Sentence classification task: Does the sentenc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>2025-03-13 18:00:08.645871</td>\n",
       "      <td>1424</td>\n",
       "      <td>635</td>\n",
       "      <td>161831</td>\n",
       "      <td>29141</td>\n",
       "      <td>125.999972</td>\n",
       "      <td>0.637154</td>\n",
       "      <td>Determine whether each sentence is subjective ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>2025-03-13 18:00:08.645871</td>\n",
       "      <td>1424</td>\n",
       "      <td>635</td>\n",
       "      <td>161831</td>\n",
       "      <td>29141</td>\n",
       "      <td>125.999972</td>\n",
       "      <td>0.634519</td>\n",
       "      <td>Analyze the given sentence to determine whethe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>2025-03-13 18:00:08.645871</td>\n",
       "      <td>1424</td>\n",
       "      <td>635</td>\n",
       "      <td>161831</td>\n",
       "      <td>29141</td>\n",
       "      <td>125.999972</td>\n",
       "      <td>0.616667</td>\n",
       "      <td>Using your understanding of subjectivity vs. o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>2025-03-13 18:00:08.645871</td>\n",
       "      <td>1424</td>\n",
       "      <td>635</td>\n",
       "      <td>161831</td>\n",
       "      <td>29141</td>\n",
       "      <td>125.999972</td>\n",
       "      <td>0.605204</td>\n",
       "      <td>Read the following sentence and classify it as...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   step                   timestamp  input_tokens_meta_llm  \\\n",
       "0     1  2025-03-13 18:00:08.645871                   1424   \n",
       "1     1  2025-03-13 18:00:08.645871                   1424   \n",
       "2     1  2025-03-13 18:00:08.645871                   1424   \n",
       "3     1  2025-03-13 18:00:08.645871                   1424   \n",
       "4     1  2025-03-13 18:00:08.645871                   1424   \n",
       "5     1  2025-03-13 18:00:08.645871                   1424   \n",
       "6     1  2025-03-13 18:00:08.645871                   1424   \n",
       "7     1  2025-03-13 18:00:08.645871                   1424   \n",
       "8     1  2025-03-13 18:00:08.645871                   1424   \n",
       "9     1  2025-03-13 18:00:08.645871                   1424   \n",
       "\n",
       "   output_tokens_meta_llm  input_tokens_downstream_llm  \\\n",
       "0                     635                       161831   \n",
       "1                     635                       161831   \n",
       "2                     635                       161831   \n",
       "3                     635                       161831   \n",
       "4                     635                       161831   \n",
       "5                     635                       161831   \n",
       "6                     635                       161831   \n",
       "7                     635                       161831   \n",
       "8                     635                       161831   \n",
       "9                     635                       161831   \n",
       "\n",
       "   output_tokens_downstream_llm  time_elapsed     score  \\\n",
       "0                         29141    125.999972  0.762846   \n",
       "1                         29141    125.999972  0.732345   \n",
       "2                         29141    125.999972  0.720422   \n",
       "3                         29141    125.999972  0.676153   \n",
       "4                         29141    125.999972  0.657312   \n",
       "5                         29141    125.999972  0.640975   \n",
       "6                         29141    125.999972  0.637154   \n",
       "7                         29141    125.999972  0.634519   \n",
       "8                         29141    125.999972  0.616667   \n",
       "9                         29141    125.999972  0.605204   \n",
       "\n",
       "                                              prompt  \n",
       "0  Linguistic analysis: Examine the provided sent...  \n",
       "1  You are tasked with analyzing each sentence to...  \n",
       "2  Task: Classify each sentence as either subject...  \n",
       "3  Classify as objective (fact-based) or subjecti...  \n",
       "4  Subjectivity analysis task: Examine the senten...  \n",
       "5  Sentence classification task: Does the sentenc...  \n",
       "6  Determine whether each sentence is subjective ...  \n",
       "7  Analyze the given sentence to determine whethe...  \n",
       "8  Using your understanding of subjectivity vs. o...  \n",
       "9  Read the following sentence and classify it as...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"step\"] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "step",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "input_tokens_meta_llm",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "output_tokens_meta_llm",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "input_tokens_downstream_llm",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "output_tokens_downstream_llm",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "time_elapsed",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "score",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "cum_input_tokens",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "score_max",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "060d9b06-3ac3-45db-b8a3-5b6f26a8bd0c",
       "rows": [
        [
         "0",
         "1",
         "1424.0",
         "635.0",
         "161831.0",
         "29141.0",
         "125.999972",
         "0.6683596837944664",
         "161831.0",
         "0.7628458498023714"
        ],
        [
         "1",
         "2",
         "1627.0",
         "880.0",
         "568037.0",
         "140056.0",
         "238.08442800000003",
         "0.6507679277244495",
         "729868.0",
         "0.6918501788067006"
        ],
        [
         "2",
         "3",
         "1814.0",
         "955.0",
         "100754.0",
         "41299.0",
         "60.76749600000001",
         "0.6831488801054019",
         "830622.0",
         "0.7378458498023716"
        ],
        [
         "3",
         "4",
         "1775.0",
         "916.0",
         "130451.0",
         "43164.0",
         "70.440861",
         "0.6689380764163373",
         "961073.0",
         "0.7161791831357048"
        ],
        [
         "4",
         "5",
         "1701.0",
         "911.0",
         "160556.0",
         "64794.0",
         "96.849998",
         "0.6720121504904114",
         "1121629.0",
         "0.7146977016542234"
        ],
        [
         "5",
         "6",
         "1670.0",
         "852.0",
         "20320.0",
         "8610.0",
         "14.442060000000001",
         "0.7512714097496707",
         "1141949.0",
         "0.7961791831357047"
        ],
        [
         "6",
         "7",
         "1833.0",
         "1039.0",
         "54166.0",
         "18740.0",
         "31.208828",
         "0.7512714097496705",
         "1196115.0",
         "0.7961791831357047"
        ],
        [
         "7",
         "8",
         "1684.0",
         "894.0",
         "168342.0",
         "87674.0",
         "111.092516",
         "0.6648814229249013",
         "1364457.0",
         "0.7161791831357048"
        ],
        [
         "8",
         "9",
         "1816.0",
         "1005.0",
         "104550.0",
         "37804.0",
         "73.218236",
         "0.6648814229249013",
         "1469007.0",
         "0.7161791831357048"
        ],
        [
         "9",
         "10",
         "1736.0",
         "850.0",
         "55772.0",
         "37234.0",
         "46.204789",
         "0.6979940711462451",
         "1524779.0",
         "0.746179183135705"
        ],
        [
         "10",
         "11",
         "1843.0",
         "917.0",
         "55443.0",
         "30974.0",
         "45.989948",
         "0.7021607378129118",
         "1580222.0",
         "0.7537549407114625"
        ],
        [
         "11",
         "12",
         "1882.0",
         "966.0",
         "166284.0",
         "96439.0",
         "114.86284",
         "0.6731620553359684",
         "1746506.0",
         "0.7161791831357048"
        ],
        [
         "12",
         "13",
         "1862.0",
         "1057.0",
         "194160.0",
         "47034.0",
         "103.56298",
         "0.6814321475625824",
         "1940666.0",
         "0.7161791831357048"
        ],
        [
         "13",
         "14",
         "1810.0",
         "910.0",
         "106826.0",
         "30145.0",
         "70.892353",
         "0.6942592592592592",
         "2047492.0",
         "0.7295125164690381"
        ],
        [
         "14",
         "15",
         "1787.0",
         "900.0",
         "169093.0",
         "52164.0",
         "96.218647",
         "0.6861554677206851",
         "2216585.0",
         "0.7161791831357048"
        ],
        [
         "15",
         "16",
         "1835.0",
         "968.0",
         "250800.0",
         "83111.0",
         "132.536603",
         "0.6924993412384717",
         "2467385.0",
         "0.7161791831357048"
        ],
        [
         "16",
         "17",
         "2117.0",
         "1210.0",
         "97587.0",
         "74672.0",
         "88.986781",
         "0.6924993412384717",
         "2564972.0",
         "0.7161791831357048"
        ],
        [
         "17",
         "18",
         "1922.0",
         "1029.0",
         "103130.0",
         "56579.0",
         "83.04292",
         "0.6924993412384717",
         "2668102.0",
         "0.7161791831357048"
        ],
        [
         "18",
         "19",
         "2080.0",
         "1025.0",
         "81450.0",
         "34126.0",
         "51.426475",
         "0.6961660079051384",
         "2749552.0",
         "0.7432147562582346"
        ],
        [
         "19",
         "20",
         "2410.0",
         "1576.0",
         "88667.0",
         "40295.0",
         "58.43257200000001",
         "0.6918326745718051",
         "2838219.0",
         "0.7113438735177867"
        ],
        [
         "20",
         "21",
         "1798.0",
         "936.0",
         "69646.0",
         "13391.0",
         "41.994702",
         "0.7122771190162495",
         "2907865.0",
         "0.7861001317523058"
        ],
        [
         "21",
         "22",
         "2085.0",
         "1154.0",
         "115851.0",
         "39132.0",
         "77.708483",
         "0.6935469602860908",
         "3023716.0",
         "0.7217861848296631"
        ]
       ],
       "shape": {
        "columns": 9,
        "rows": 22
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>step</th>\n",
       "      <th>input_tokens_meta_llm</th>\n",
       "      <th>output_tokens_meta_llm</th>\n",
       "      <th>input_tokens_downstream_llm</th>\n",
       "      <th>output_tokens_downstream_llm</th>\n",
       "      <th>time_elapsed</th>\n",
       "      <th>score</th>\n",
       "      <th>cum_input_tokens</th>\n",
       "      <th>score_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1424.0</td>\n",
       "      <td>635.0</td>\n",
       "      <td>161831.0</td>\n",
       "      <td>29141.0</td>\n",
       "      <td>125.999972</td>\n",
       "      <td>0.668360</td>\n",
       "      <td>161831.0</td>\n",
       "      <td>0.762846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1627.0</td>\n",
       "      <td>880.0</td>\n",
       "      <td>568037.0</td>\n",
       "      <td>140056.0</td>\n",
       "      <td>238.084428</td>\n",
       "      <td>0.650768</td>\n",
       "      <td>729868.0</td>\n",
       "      <td>0.691850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1814.0</td>\n",
       "      <td>955.0</td>\n",
       "      <td>100754.0</td>\n",
       "      <td>41299.0</td>\n",
       "      <td>60.767496</td>\n",
       "      <td>0.683149</td>\n",
       "      <td>830622.0</td>\n",
       "      <td>0.737846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1775.0</td>\n",
       "      <td>916.0</td>\n",
       "      <td>130451.0</td>\n",
       "      <td>43164.0</td>\n",
       "      <td>70.440861</td>\n",
       "      <td>0.668938</td>\n",
       "      <td>961073.0</td>\n",
       "      <td>0.716179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1701.0</td>\n",
       "      <td>911.0</td>\n",
       "      <td>160556.0</td>\n",
       "      <td>64794.0</td>\n",
       "      <td>96.849998</td>\n",
       "      <td>0.672012</td>\n",
       "      <td>1121629.0</td>\n",
       "      <td>0.714698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>1670.0</td>\n",
       "      <td>852.0</td>\n",
       "      <td>20320.0</td>\n",
       "      <td>8610.0</td>\n",
       "      <td>14.442060</td>\n",
       "      <td>0.751271</td>\n",
       "      <td>1141949.0</td>\n",
       "      <td>0.796179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>1833.0</td>\n",
       "      <td>1039.0</td>\n",
       "      <td>54166.0</td>\n",
       "      <td>18740.0</td>\n",
       "      <td>31.208828</td>\n",
       "      <td>0.751271</td>\n",
       "      <td>1196115.0</td>\n",
       "      <td>0.796179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>1684.0</td>\n",
       "      <td>894.0</td>\n",
       "      <td>168342.0</td>\n",
       "      <td>87674.0</td>\n",
       "      <td>111.092516</td>\n",
       "      <td>0.664881</td>\n",
       "      <td>1364457.0</td>\n",
       "      <td>0.716179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1816.0</td>\n",
       "      <td>1005.0</td>\n",
       "      <td>104550.0</td>\n",
       "      <td>37804.0</td>\n",
       "      <td>73.218236</td>\n",
       "      <td>0.664881</td>\n",
       "      <td>1469007.0</td>\n",
       "      <td>0.716179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>1736.0</td>\n",
       "      <td>850.0</td>\n",
       "      <td>55772.0</td>\n",
       "      <td>37234.0</td>\n",
       "      <td>46.204789</td>\n",
       "      <td>0.697994</td>\n",
       "      <td>1524779.0</td>\n",
       "      <td>0.746179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>1843.0</td>\n",
       "      <td>917.0</td>\n",
       "      <td>55443.0</td>\n",
       "      <td>30974.0</td>\n",
       "      <td>45.989948</td>\n",
       "      <td>0.702161</td>\n",
       "      <td>1580222.0</td>\n",
       "      <td>0.753755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>1882.0</td>\n",
       "      <td>966.0</td>\n",
       "      <td>166284.0</td>\n",
       "      <td>96439.0</td>\n",
       "      <td>114.862840</td>\n",
       "      <td>0.673162</td>\n",
       "      <td>1746506.0</td>\n",
       "      <td>0.716179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>1862.0</td>\n",
       "      <td>1057.0</td>\n",
       "      <td>194160.0</td>\n",
       "      <td>47034.0</td>\n",
       "      <td>103.562980</td>\n",
       "      <td>0.681432</td>\n",
       "      <td>1940666.0</td>\n",
       "      <td>0.716179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>1810.0</td>\n",
       "      <td>910.0</td>\n",
       "      <td>106826.0</td>\n",
       "      <td>30145.0</td>\n",
       "      <td>70.892353</td>\n",
       "      <td>0.694259</td>\n",
       "      <td>2047492.0</td>\n",
       "      <td>0.729513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>1787.0</td>\n",
       "      <td>900.0</td>\n",
       "      <td>169093.0</td>\n",
       "      <td>52164.0</td>\n",
       "      <td>96.218647</td>\n",
       "      <td>0.686155</td>\n",
       "      <td>2216585.0</td>\n",
       "      <td>0.716179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>1835.0</td>\n",
       "      <td>968.0</td>\n",
       "      <td>250800.0</td>\n",
       "      <td>83111.0</td>\n",
       "      <td>132.536603</td>\n",
       "      <td>0.692499</td>\n",
       "      <td>2467385.0</td>\n",
       "      <td>0.716179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>2117.0</td>\n",
       "      <td>1210.0</td>\n",
       "      <td>97587.0</td>\n",
       "      <td>74672.0</td>\n",
       "      <td>88.986781</td>\n",
       "      <td>0.692499</td>\n",
       "      <td>2564972.0</td>\n",
       "      <td>0.716179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>1922.0</td>\n",
       "      <td>1029.0</td>\n",
       "      <td>103130.0</td>\n",
       "      <td>56579.0</td>\n",
       "      <td>83.042920</td>\n",
       "      <td>0.692499</td>\n",
       "      <td>2668102.0</td>\n",
       "      <td>0.716179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>2080.0</td>\n",
       "      <td>1025.0</td>\n",
       "      <td>81450.0</td>\n",
       "      <td>34126.0</td>\n",
       "      <td>51.426475</td>\n",
       "      <td>0.696166</td>\n",
       "      <td>2749552.0</td>\n",
       "      <td>0.743215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>2410.0</td>\n",
       "      <td>1576.0</td>\n",
       "      <td>88667.0</td>\n",
       "      <td>40295.0</td>\n",
       "      <td>58.432572</td>\n",
       "      <td>0.691833</td>\n",
       "      <td>2838219.0</td>\n",
       "      <td>0.711344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>1798.0</td>\n",
       "      <td>936.0</td>\n",
       "      <td>69646.0</td>\n",
       "      <td>13391.0</td>\n",
       "      <td>41.994702</td>\n",
       "      <td>0.712277</td>\n",
       "      <td>2907865.0</td>\n",
       "      <td>0.786100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>2085.0</td>\n",
       "      <td>1154.0</td>\n",
       "      <td>115851.0</td>\n",
       "      <td>39132.0</td>\n",
       "      <td>77.708483</td>\n",
       "      <td>0.693547</td>\n",
       "      <td>3023716.0</td>\n",
       "      <td>0.721786</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    step  input_tokens_meta_llm  output_tokens_meta_llm  \\\n",
       "0      1                 1424.0                   635.0   \n",
       "1      2                 1627.0                   880.0   \n",
       "2      3                 1814.0                   955.0   \n",
       "3      4                 1775.0                   916.0   \n",
       "4      5                 1701.0                   911.0   \n",
       "5      6                 1670.0                   852.0   \n",
       "6      7                 1833.0                  1039.0   \n",
       "7      8                 1684.0                   894.0   \n",
       "8      9                 1816.0                  1005.0   \n",
       "9     10                 1736.0                   850.0   \n",
       "10    11                 1843.0                   917.0   \n",
       "11    12                 1882.0                   966.0   \n",
       "12    13                 1862.0                  1057.0   \n",
       "13    14                 1810.0                   910.0   \n",
       "14    15                 1787.0                   900.0   \n",
       "15    16                 1835.0                   968.0   \n",
       "16    17                 2117.0                  1210.0   \n",
       "17    18                 1922.0                  1029.0   \n",
       "18    19                 2080.0                  1025.0   \n",
       "19    20                 2410.0                  1576.0   \n",
       "20    21                 1798.0                   936.0   \n",
       "21    22                 2085.0                  1154.0   \n",
       "\n",
       "    input_tokens_downstream_llm  output_tokens_downstream_llm  time_elapsed  \\\n",
       "0                      161831.0                       29141.0    125.999972   \n",
       "1                      568037.0                      140056.0    238.084428   \n",
       "2                      100754.0                       41299.0     60.767496   \n",
       "3                      130451.0                       43164.0     70.440861   \n",
       "4                      160556.0                       64794.0     96.849998   \n",
       "5                       20320.0                        8610.0     14.442060   \n",
       "6                       54166.0                       18740.0     31.208828   \n",
       "7                      168342.0                       87674.0    111.092516   \n",
       "8                      104550.0                       37804.0     73.218236   \n",
       "9                       55772.0                       37234.0     46.204789   \n",
       "10                      55443.0                       30974.0     45.989948   \n",
       "11                     166284.0                       96439.0    114.862840   \n",
       "12                     194160.0                       47034.0    103.562980   \n",
       "13                     106826.0                       30145.0     70.892353   \n",
       "14                     169093.0                       52164.0     96.218647   \n",
       "15                     250800.0                       83111.0    132.536603   \n",
       "16                      97587.0                       74672.0     88.986781   \n",
       "17                     103130.0                       56579.0     83.042920   \n",
       "18                      81450.0                       34126.0     51.426475   \n",
       "19                      88667.0                       40295.0     58.432572   \n",
       "20                      69646.0                       13391.0     41.994702   \n",
       "21                     115851.0                       39132.0     77.708483   \n",
       "\n",
       "       score  cum_input_tokens  score_max  \n",
       "0   0.668360          161831.0   0.762846  \n",
       "1   0.650768          729868.0   0.691850  \n",
       "2   0.683149          830622.0   0.737846  \n",
       "3   0.668938          961073.0   0.716179  \n",
       "4   0.672012         1121629.0   0.714698  \n",
       "5   0.751271         1141949.0   0.796179  \n",
       "6   0.751271         1196115.0   0.796179  \n",
       "7   0.664881         1364457.0   0.716179  \n",
       "8   0.664881         1469007.0   0.716179  \n",
       "9   0.697994         1524779.0   0.746179  \n",
       "10  0.702161         1580222.0   0.753755  \n",
       "11  0.673162         1746506.0   0.716179  \n",
       "12  0.681432         1940666.0   0.716179  \n",
       "13  0.694259         2047492.0   0.729513  \n",
       "14  0.686155         2216585.0   0.716179  \n",
       "15  0.692499         2467385.0   0.716179  \n",
       "16  0.692499         2564972.0   0.716179  \n",
       "17  0.692499         2668102.0   0.716179  \n",
       "18  0.696166         2749552.0   0.743215  \n",
       "19  0.691833         2838219.0   0.711344  \n",
       "20  0.712277         2907865.0   0.786100  \n",
       "21  0.693547         3023716.0   0.721786  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# group df by step and get the mean of the values (ignore stings)\n",
    "df_grouped = df.groupby(\"step\", as_index=False).mean(numeric_only=True)\n",
    "df_grouped[\"cum_input_tokens\"] = df_grouped[\"input_tokens_downstream_llm\"].cumsum()\n",
    "\n",
    "# join the maximum score for each step\n",
    "df_grouped = df_grouped.join(\n",
    "    df.groupby(\"step\", as_index=False).max()[[\"step\", \"score\"]].set_index(\"step\"),\n",
    "    on=\"step\",\n",
    "    rsuffix=\"_max\",\n",
    ")\n",
    "\n",
    "df_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(df_grouped[\"step\"], df_grouped[\"score_max\"]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6918501788067006, 0.7961791831357047)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot token count vs step and adapt y-axis to min and max\n",
    "column = \"score_max\"\n",
    "plt.bar(df_grouped[\"step\"], df_grouped[column])\n",
    "plt.ylim(df_grouped[column].min(), df_grouped[column].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiMAAAGdCAYAAADAAnMpAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjEsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvc2/+5QAAAAlwSFlzAAAPYQAAD2EBqD+naQAAH+JJREFUeJzt3Q90XvVdP/BPG0hCgRZYIYGsIwKOUoEU0yUURLazjqo7OOb0BJwm5rB4HNSD5GyObqMdf1zY2Gr8k1GHRFRkRHZAVDids9J5OA3mmMpxTFbtJmv5k6Z1NoHikpnkd+71l6yhSelTUr5NntfrnG/Te/u99/k+fXqTd79/7p03NjY2FgAAicxP9cIAABlhBABIShgBAJISRgCApIQRACApYQQASEoYAQCSEkYAgKSOi1lgdHQ0XnrppTj55JNj3rx5qZsDAByG7L6qr7zySpx11lkxf/782R1GsiCyZMmS1M0AAI7Arl274u1vf/vsDiNZj8j4m1m4cGHq5gAAh2FwcDDvTBj/OT6rw8j40EwWRIQRAJhd3miKhQmsAEBSwggAkJQwAgAkJYwAAEkJIwBAUsIIAJCUMAIAJCWMAACzL4x0dHREdXV1lJeXR319ffT09Byyfnt7e5x//vlxwgkn5Hdiu/nmm+MHP/jBkbYZACjmMNLV1RWtra2xfv362LZtW9TU1MTq1aujv79/yvoPPvhg3HLLLXn95557Lu677778HJ/85Cdnov0AQLGFkQ0bNkRLS0s0NzfHsmXLYuPGjbFgwYLo7Oycsv7WrVvj8ssvj1/+5V/Oe1OuuuqquO66696wNwUAKA4FhZHh4eHo7e2NVatW/egE8+fn293d3VMec9lll+XHjIeP7373u/HEE0/Ez/3cz73ZtgMAc0BBD8rbu3dvjIyMREVFxaT92fa3v/3tKY/JekSy437qp34qxsbG4n//93/jN37jNw45TDM0NJSXA5/6BwDMTUd9Nc2WLVvis5/9bHzpS1/K55g88sgj8fjjj8cdd9wx7TFtbW2xaNGiiZJNegUA5qZ5Y1l3RQHDNNn8kK9+9atxzTXXTOxvamqKffv2xWOPPXbQMVdccUVceumlcffdd0/se+CBB+LXf/3X49VXX82HeQ6nZyQLJAMDA7Fw4cJC3yOzWPUtj7+p45+/6/0zer6pzgnA1LKf31mnwhv9/C6oZ6S0tDRqa2tj8+bNE/tGR0fz7ZUrV055zGuvvXZQ4CgpKcm/TpeDysrK8kYfWACAuamgOSOZbFlv1hOyYsWKqKury+8hsn///nx1TaaxsTGqqqryoZbM1Vdfna/AueSSS/J7kuzYsSNuvfXWfP94KAEAilfBYaShoSH27NkT69ati76+vli+fHls2rRpYlLrzp07J/WEfPrTn4558+blX1988cU4/fTT8yDyO7/zOzP7TgCAuT9n5Fgfc2LuMWcEYPY63J/fBfeMAADHzn+y5gIPygMAkhJGAICkhBEAIClhBABIShgBAJISRgCApIQRACApYQQASEoYAQCSKvo7sLo9OACkpWcEAEhKGAEAkhJGAICkin7OCHBkzLcCZoqeEQAgKWEEAEjKMA0UAUMqwLFMzwgAkJSeEQDmjDfbC6gHMA09IwBAUnpGZglpH4C5Ss8IAJCUMAIAJCWMAABJmTMCUAD3bIGZp2cEAEhKGAEAkjJMAwCzXPUsv/2DnhEAIClhBABIyjBNkToaKwKKdZXBsfh3ORv/Ho/G+54t/yaPxuc9G/4ui/XfOQfTMwIAJKVnBACmMVt614qyZ6SjoyOqq6ujvLw86uvro6enZ9q67373u2PevHkHlfe/34cDABxBGOnq6orW1tZYv359bNu2LWpqamL16tXR398/Zf1HHnkkXn755Yny7LPPRklJSfzSL/3STLQfACi2MLJhw4ZoaWmJ5ubmWLZsWWzcuDEWLFgQnZ2dU9Y/7bTTorKycqJ8/etfz+sLIwBAwWFkeHg4ent7Y9WqVRP75s+fn293d3cf1jnuu+++uPbaa+PEE0+cts7Q0FAMDg5OKgDA3FRQGNm7d2+MjIxERUXFpP3Zdl9f3xsen80tyYZpPvKRjxyyXltbWyxatGiiLFmypJBmAgCzyFu6tDfrFbnooouirq7ukPXWrl0bAwMDE2XXrl1vWRsBgGN4ae/ixYvzyae7d++etD/bzuaDHMr+/fvjoYceittvv/0NX6esrCwvAMDcV1AYKS0tjdra2ti8eXNcc801+b7R0dF8e82aNYc89uGHH87ngvzKr/xKzHXuKggAR/GmZ9my3qamplixYkU+3NLe3p73emSrazKNjY1RVVWVz/t4/RBNFmDe9ra3FfqSAMAcVnAYaWhoiD179sS6devySavLly+PTZs2TUxq3blzZ77C5kDbt2+Pp556Kv7u7/5u5loOABTv7eCzIZnphmW2bNly0L7zzz8/xsbGjuSlAIA5zoPyAICkhBEAIClhBABIShgBAJISRgCApIQRACApYQQASEoYAQCSEkYAgKSEEQAgKWEEAEhKGAEAkhJGAICkhBEAIClhBABIShgBAJISRgCApIQRACApYQQASEoYAQCSEkYAgKSEEQAgKWEEAEhKGAEAkhJGAICkhBEAIClhBABIShgBAJISRgCApIQRACApYQQASEoYAQCSEkYAgNkXRjo6OqK6ujrKy8ujvr4+enp6Dll/3759ceONN8aZZ54ZZWVl8c53vjOeeOKJI20zADCHHFfoAV1dXdHa2hobN27Mg0h7e3usXr06tm/fHmecccZB9YeHh+N973tf/mdf/epXo6qqKr73ve/FKaecMlPvAQAopjCyYcOGaGlpiebm5nw7CyWPP/54dHZ2xi233HJQ/Wz/97///di6dWscf/zx+b6sVwUAoOBhmqyXo7e3N1atWjWxb/78+fl2d3f3lMf89V//daxcuTIfpqmoqIgLL7wwPvvZz8bIyMi0rzM0NBSDg4OTCgAwNxUURvbu3ZuHiCxUHCjb7uvrm/KY7373u/nwTHZcNk/k1ltvjS9+8Ytx5513Tvs6bW1tsWjRoomyZMmSQpoJAMwiR301zejoaD5f5Mtf/nLU1tZGQ0NDfOpTn8qHd6azdu3aGBgYmCi7du062s0EAGbDnJHFixdHSUlJ7N69e9L+bLuysnLKY7IVNNlckey4cRdccEHek5IN+5SWlh50TLbiJisAwNxXUM9IFhyy3o3NmzdP6vnItrN5IVO5/PLLY8eOHXm9cf/+7/+eh5SpgggAUFwKHqbJlvXee++98ad/+qfx3HPPxUc/+tHYv3//xOqaxsbGfJhlXPbn2Wqam266KQ8h2cqbbAJrNqEVAKDgpb3ZnI89e/bEunXr8qGW5cuXx6ZNmyYmte7cuTNfYTMum3z6ta99LW6++ea4+OKL8/uMZMHkE5/4xMy+EwCgOMJIZs2aNXmZypYtWw7alw3hPP3000fyUgDAHOfZNABAUsIIAJCUMAIAJCWMAABJCSMAQFLCCACQlDACACQljAAASQkjAEBSwggAkJQwAgAkJYwAAEkJIwBAUsIIAJCUMAIAJCWMAABJCSMAQFLCCACQlDACACQljAAASQkjAEBSwggAkJQwAgAkJYwAAEkJIwBAUsIIAJCUMAIAJCWMAABJCSMAQFLCCACQlDACACQljAAASQkjAMDsCyMdHR1RXV0d5eXlUV9fHz09PdPWvf/++2PevHmTSnYcAMARhZGurq5obW2N9evXx7Zt26KmpiZWr14d/f390x6zcOHCePnllyfK9773PX/7AMCRhZENGzZES0tLNDc3x7Jly2Ljxo2xYMGC6OzsnPaYrDeksrJyolRUVBT6sgDAHFVQGBkeHo7e3t5YtWrVj04wf36+3d3dPe1xr776apx99tmxZMmS+MAHPhDf+ta3Dvk6Q0NDMTg4OKkAAHNTQWFk7969MTIyclDPRrbd19c35THnn39+3mvy2GOPxQMPPBCjo6Nx2WWXxQsvvDDt67S1tcWiRYsmShZiAIC56aivplm5cmU0NjbG8uXL48orr4xHHnkkTj/99PijP/qjaY9Zu3ZtDAwMTJRdu3Yd7WYCAIkcV0jlxYsXR0lJSezevXvS/mw7mwtyOI4//vi45JJLYseOHdPWKSsrywsAMPcV1DNSWloatbW1sXnz5ol92bBLtp31gByObJjnm9/8Zpx55pmFtxYAKO6ekUy2rLepqSlWrFgRdXV10d7eHvv3789X12SyIZmqqqp83kfm9ttvj0svvTTOO++82LdvX9x999350t6PfOQjM/9uAIC5H0YaGhpiz549sW7dunzSajYXZNOmTROTWnfu3JmvsBn33//93/lS4KzuqaeemvesbN26NV8WDABQcBjJrFmzJi9T2bJly6Tt3/3d380LAMBUPJsGAEhKGAEAkhJGAICkhBEAIClhBABIShgBAJISRgCApIQRACApYQQASEoYAQCSEkYAgKSEEQAgKWEEAEhKGAEAkhJGAICkhBEAIClhBABIShgBAJISRgCApIQRACApYQQASEoYAQCSEkYAgKSEEQAgKWEEAEhKGAEAkhJGAICkhBEAIClhBABIShgBAJISRgCApIQRACApYQQAmH1hpKOjI6qrq6O8vDzq6+ujp6fnsI576KGHYt68eXHNNdccycsCAHNQwWGkq6srWltbY/369bFt27aoqamJ1atXR39//yGPe/755+NjH/tYXHHFFW+mvQBAsYeRDRs2REtLSzQ3N8eyZcti48aNsWDBgujs7Jz2mJGRkfjwhz8ct912W5xzzjlvts0AQLGGkeHh4ejt7Y1Vq1b96ATz5+fb3d3d0x53++23xxlnnBHXX3/9Yb3O0NBQDA4OTioAwNxUUBjZu3dv3stRUVExaX+23dfXN+UxTz31VNx3331x7733HvbrtLW1xaJFiybKkiVLCmkmADCLHNXVNK+88kr86q/+ah5EFi9efNjHrV27NgYGBibKrl27jmYzAYCEjiukchYoSkpKYvfu3ZP2Z9uVlZUH1f/Od76TT1y9+uqrJ/aNjo7+3wsfd1xs3749zj333IOOKysrywsAMPcV1DNSWloatbW1sXnz5knhItteuXLlQfWXLl0a3/zmN+OZZ56ZKD//8z8f73nPe/LfG34BAArqGclky3qbmppixYoVUVdXF+3t7bF///58dU2msbExqqqq8nkf2X1ILrzwwknHn3LKKfnX1+8HAIpTwWGkoaEh9uzZE+vWrcsnrS5fvjw2bdo0Mal1586d+QobAICjEkYya9asyctUtmzZcshj77///iN5SQBgjtKFAQAkJYwAAEkJIwBAUsIIAJCUMAIAJCWMAABJCSMAQFLCCACQlDACACQljAAASQkjAEBSwggAkJQwAgAkJYwAAEkJIwBAUsIIAJCUMAIAJCWMAABJCSMAQFLCCACQlDACACQljAAASQkjAEBSwggAkJQwAgAkJYwAAEkJIwBAUsIIAJCUMAIAJCWMAABJCSMAQFLCCACQlDACAMy+MNLR0RHV1dVRXl4e9fX10dPTM23dRx55JFasWBGnnHJKnHjiibF8+fL48z//8zfTZgCgmMNIV1dXtLa2xvr162Pbtm1RU1MTq1evjv7+/inrn3baafGpT30quru741//9V+jubk5L1/72tdmov0AQLGFkQ0bNkRLS0seKJYtWxYbN26MBQsWRGdn55T13/3ud8cHP/jBuOCCC+Lcc8+Nm266KS6++OJ46qmnZqL9AEAxhZHh4eHo7e2NVatW/egE8+fn21nPxxsZGxuLzZs3x/bt2+Onf/qnj6zFAMCcclwhlffu3RsjIyNRUVExaX+2/e1vf3va4wYGBqKqqiqGhoaipKQkvvSlL8X73ve+aetn9bIybnBwsJBmAgBzNYwcqZNPPjmeeeaZePXVV/OekWzOyTnnnJMP4Uylra0tbrvttreiaQDAbAojixcvzns2du/ePWl/tl1ZWTntcdlQznnnnZf/PltN89xzz+WBY7owsnbt2jywHNgzsmTJkkKaCgDMxTkjpaWlUVtbm/dujBsdHc23V65cedjnyY45cBjm9crKymLhwoWTCgAwNxU8TJP1WDQ1NeX3Dqmrq4v29vbYv39/vrom09jYmM8PyXo+MtnXrG62kiYLIE888UR+n5F77rln5t8NADD3w0hDQ0Ps2bMn1q1bF319ffmwy6ZNmyYmte7cuTMflhmXBZUbbrghXnjhhTjhhBNi6dKl8cADD+TnAQA4ogmsa9asyctUtmzZMmn7zjvvzAsAwFQ8mwYASEoYAQCSEkYAgKSEEQAgKWEEAEhKGAEAkhJGAICkhBEAIClhBABIShgBAJISRgCApIQRACApYQQASEoYAQCSEkYAgKSEEQAgKWEEAEhKGAEAkhJGAICkhBEAIClhBABIShgBAJISRgCApIQRACApYQQASEoYAQCSEkYAgKSEEQAgKWEEAEhKGAEAkhJGAICkhBEAIClhBABIShgBAGZfGOno6Ijq6uooLy+P+vr66OnpmbbuvffeG1dccUWceuqpeVm1atUh6wMAxaXgMNLV1RWtra2xfv362LZtW9TU1MTq1aujv79/yvpbtmyJ6667Lp588sno7u6OJUuWxFVXXRUvvvjiTLQfACi2MLJhw4ZoaWmJ5ubmWLZsWWzcuDEWLFgQnZ2dU9b/i7/4i7jhhhti+fLlsXTp0vjjP/7jGB0djc2bN89E+wGAYgojw8PD0dvbmw+1TJxg/vx8O+v1OByvvfZa/PCHP4zTTjtt2jpDQ0MxODg4qQAAc1NBYWTv3r0xMjISFRUVk/Zn2319fYd1jk984hNx1llnTQo0r9fW1haLFi2aKNnQDgAwN72lq2nuuuuueOihh+LRRx/NJ79OZ+3atTEwMDBRdu3a9VY2EwB4Cx1XSOXFixdHSUlJ7N69e9L+bLuysvKQx37hC1/Iw8jf//3fx8UXX3zIumVlZXkBAOa+gnpGSktLo7a2dtLk0/HJqCtXrpz2uM9//vNxxx13xKZNm2LFihVvrsUAQPH2jGSyZb1NTU15qKirq4v29vbYv39/vrom09jYGFVVVfm8j8znPve5WLduXTz44IP5vUnG55acdNJJeQEAilvBYaShoSH27NmTB4wsWGRLdrMej/FJrTt37sxX2Iy755578lU4v/iLvzjpPNl9Sj7zmc/MxHsAAIopjGTWrFmTl+lucnag559//shaBgAUBc+mAQCSEkYAgKSEEQAgKWEEAEhKGAEAkhJGAICkhBEAIClhBABIShgBAJISRgCApIQRACApYQQASEoYAQCSEkYAgKSEEQAgKWEEAEhKGAEAkhJGAICkhBEAIClhBABIShgBAJISRgCApIQRACApYQQASEoYAQCSEkYAgKSEEQAgKWEEAEhKGAEAkhJGAICkhBEAIClhBABIShgBAGZfGOno6Ijq6uooLy+P+vr66Onpmbbut771rfjQhz6U1583b160t7e/mfYCAMUeRrq6uqK1tTXWr18f27Zti5qamli9enX09/dPWf+1116Lc845J+66666orKyciTYDAMUcRjZs2BAtLS3R3Nwcy5Yti40bN8aCBQuis7Nzyvrvete74u67745rr702ysrKZqLNAECxhpHh4eHo7e2NVatW/egE8+fn293d3TPWqKGhoRgcHJxUAIC5qaAwsnfv3hgZGYmKiopJ+7Ptvr6+GWtUW1tbLFq0aKIsWbJkxs4NABxbjsnVNGvXro2BgYGJsmvXrtRNAgCOkuMKqbx48eIoKSmJ3bt3T9qfbc/k5NRsbon5JQBQHArqGSktLY3a2trYvHnzxL7R0dF8e+XKlUejfQDAHFdQz0gmW9bb1NQUK1asiLq6uvy+Ifv3789X12QaGxujqqoqn/cxPun13/7t3yZ+/+KLL8YzzzwTJ510Upx33nkz/X4AgLkeRhoaGmLPnj2xbt26fNLq8uXLY9OmTROTWnfu3JmvsBn30ksvxSWXXDKx/YUvfCEvV155ZWzZsmWm3gcAUCxhJLNmzZq8TOX1ASO78+rY2NiRtQ4AmPOOydU0AEDxEEYAgKSEEQAgKWEEAEhKGAEAkhJGAICkhBEAIClhBABIShgBAJISRgCApIQRACApYQQASEoYAQCSEkYAgKSEEQAgKWEEAEhKGAEAkhJGAICkhBEAIClhBABIShgBAJISRgCApIQRACApYQQASEoYAQCSEkYAgKSEEQAgKWEEAEhKGAEAkhJGAICkhBEAIClhBABIShgBAGZfGOno6Ijq6uooLy+P+vr66OnpOWT9hx9+OJYuXZrXv+iii+KJJ5440vYCAMUeRrq6uqK1tTXWr18f27Zti5qamli9enX09/dPWX/r1q1x3XXXxfXXXx//8i//Etdcc01enn322ZloPwBQbGFkw4YN0dLSEs3NzbFs2bLYuHFjLFiwIDo7O6es/3u/93vxMz/zM/Hxj388LrjggrjjjjviJ3/yJ+MP//APZ6L9AMAsd1whlYeHh6O3tzfWrl07sW/+/PmxatWq6O7unvKYbH/Wk3KgrCflr/7qr6Z9naGhobyMGxgYyL8ODg7GTBsdeu1Nn+P17Xqz55zqfc70OY/F9300zjkb2ng0zjkb2ng0zjkb2ng0zlms3zO876N7zpkwft6xsbFDVxwrwIsvvpidbWzr1q2T9n/84x8fq6urm/KY448/fuzBBx+ctK+jo2PsjDPOmPZ11q9fn7+OoiiKoigx68uuXbsOmS8K6hl5q2Q9Lwf2poyOjsb3v//9eNvb3hbz5s07ZAJbsmRJ7Nq1KxYuXPgWtZbD4bM5tvl8jl0+m2Obz+fQsh6RV155Jc4666xD1isojCxevDhKSkpi9+7dk/Zn25WVlVMek+0vpH6mrKwsLwc65ZRTDrud2T8I/yiOTT6bY5vP59jlszm2+Xymt2jRopjRCaylpaVRW1sbmzdvntRrkW2vXLlyymOy/QfWz3z961+ftj4AUFwKHqbJhk+amppixYoVUVdXF+3t7bF///58dU2msbExqqqqoq2tLd++6aab4sorr4wvfvGL8f73vz8eeuih+Od//uf48pe/PPPvBgCY+2GkoaEh9uzZE+vWrYu+vr5Yvnx5bNq0KSoqKvI/37lzZ77CZtxll10WDz74YHz605+OT37yk/HjP/7j+UqaCy+8cGbfyf8f3snuf/L6IR7S89kc23w+xy6fzbHN5zMz5mWzWGfoXAAABfNsGgAgKWEEAEhKGAEAkhJGAICk5kwY6ejoiOrq6igvL4/6+vro6elJ3SQi4jOf+Ux+19wDy9KlS1M3qyj94z/+Y1x99dX5nRCzz+H1z4fK5rJnq+TOPPPMOOGEE/JnTv3Hf/xHsvYWmzf6fH7t137toGspewgpR192q4p3vetdcfLJJ8cZZ5yRP3l++/btk+r84Ac/iBtvvDG/U/hJJ50UH/rQhw664SdzPIx0dXXl9z/Jlldt27Ytampq8ofx9ff3p24aEfETP/ET8fLLL0+Up556KnWTilJ2P6Ds2siC+1Q+//nPx+///u/nT+L+p3/6pzjxxBPz6yj7Jkv6zyeThY8Dr6WvfOUrb2kbi9U3vvGNPGg8/fTT+U07f/jDH8ZVV12Vf2bjbr755vibv/mbePjhh/P6L730UvzCL/xC0nbPKmNzQPaQvhtvvHFie2RkZOyss84aa2trS9ou/u+hhzU1Nambwetkl/6jjz46sT06OjpWWVk5dvfdd0/s27dv31hZWdnYV77ylUStLF6v/3wyTU1NYx/4wAeStYkf6e/vzz+jb3zjGxPXSvZQ2IcffniiznPPPZfX6e7uTtjS2WPW94wMDw9Hb29v3qU8LrvpWrbd3d2dtG38n6yrP+t6Puecc+LDH/5wfmM8ji3/+Z//md/E8MDrKHueRDbk6To6dmzZsiUfJjj//PPjox/9aPzXf/1X6iYVpYGBgfzraaedln/NfgZlvSUHXj/ZcPQ73vEO189hmvVhZO/evTEyMjJxB9hx2Xb2zZW0sh9m999/f36X3nvuuSf/oXfFFVfkT3Hk2DF+rbiOjl3ZEM2f/dmf5c/6+tznPpcPBfzsz/5s/v2Pt072PLbf+q3fissvv3ziTuLZNZI9u+31D3R1/RzF28FDIbJvluMuvvjiPJycffbZ8Zd/+Zdx/fXXJ20bzCbXXnvtxO8vuuii/Ho699xz896S9773vUnbVkyyuSPPPvusuW8zbNb3jCxevDhKSkoOmrWcbVdWViZrF1PL/ufwzne+M3bs2JG6KRxg/FpxHc0e2bBn9v3PtfTWWbNmTfzt3/5tPPnkk/H2t799Yn92jWRTBvbt2zepvuuniMJI1jVWW1ubd10e2I2Wba9cuTJp2zjYq6++Gt/5znfy5aMcO37sx34s/6Z54HU0ODiYr6pxHR2bXnjhhXzOiGvp6MvmFGdB5NFHH41/+Id/yK+XA2U/g44//vhJ10+29DebH+f6KaJhmmxZb1NTU6xYsSLq6uqivb09X3LV3NycumlF72Mf+1h+74RsaCZb6pYtv856sq677rrUTSvKIHjg/6Kz+TvPPPNMPgkvm2iXjYPfeeed+ZO1s2+2t956az7xOLunAmk/n6zcdttt+b0rstCYBfrf/u3fjvPOOy9ffs3RH5rJnj7/2GOP5fcaGZ8Hkk3yzu7Jk33Nhp2zn0XZZ7Vw4cL4zd/8zTyIXHrppambPzuMzRF/8Ad/MPaOd7xjrLS0NF/q+/TTT6duEmNjYw0NDWNnnnlm/rlUVVXl2zt27EjdrKL05JNP5ksNX1+yJaPjy3tvvfXWsYqKinxJ73vf+96x7du3p2520TjU5/Paa6+NXXXVVWOnn356voT07LPPHmtpaRnr6+tL3eyiMNXnkpU/+ZM/majzP//zP2M33HDD2Kmnnjq2YMGCsQ9+8INjL7/8ctJ2zybzsl9SByIAoHjN+jkjAMDsJowAAEkJIwBAUsIIAJCUMAIAJCWMAABJCSMAQFLCCACQlDACACQljAAASQkjAEBSwggAECn9P7+FV2ireWvqAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# group df by step and get the mean of the values (ignore stings)\n",
    "df_grouped = df.groupby(\"step\", as_index=False).max(numeric_only=True)\n",
    "plt.bar(df_grouped[\"step\"], df_grouped[\"score\"]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "step",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "input_tokens_meta_llm",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "output_tokens_meta_llm",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "input_tokens_downstream_llm",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "output_tokens_downstream_llm",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "time_elapsed",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "score",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "c377a6da-3086-474e-9e43-9f4c6c0d757a",
       "rows": [
        [
         "0",
         "1",
         "1424",
         "635",
         "161831",
         "29141",
         "125.999972",
         "0.7628458498023714"
        ],
        [
         "1",
         "2",
         "1627",
         "880",
         "568037",
         "140056",
         "238.084428",
         "0.6918501788067006"
        ],
        [
         "2",
         "3",
         "1814",
         "955",
         "100754",
         "41299",
         "60.767496",
         "0.7378458498023716"
        ],
        [
         "3",
         "4",
         "1775",
         "916",
         "130451",
         "43164",
         "70.440861",
         "0.7161791831357048"
        ],
        [
         "4",
         "5",
         "1701",
         "911",
         "160556",
         "64794",
         "96.849998",
         "0.7146977016542234"
        ],
        [
         "5",
         "6",
         "1670",
         "852",
         "20320",
         "8610",
         "14.44206",
         "0.7961791831357047"
        ],
        [
         "6",
         "7",
         "1833",
         "1039",
         "54166",
         "18740",
         "31.208828",
         "0.7961791831357047"
        ],
        [
         "7",
         "8",
         "1684",
         "894",
         "168342",
         "87674",
         "111.092516",
         "0.7161791831357048"
        ],
        [
         "8",
         "9",
         "1816",
         "1005",
         "104550",
         "37804",
         "73.218236",
         "0.7161791831357048"
        ],
        [
         "9",
         "10",
         "1736",
         "850",
         "55772",
         "37234",
         "46.204789",
         "0.746179183135705"
        ],
        [
         "10",
         "11",
         "1843",
         "917",
         "55443",
         "30974",
         "45.989948",
         "0.7537549407114625"
        ],
        [
         "11",
         "12",
         "1882",
         "966",
         "166284",
         "96439",
         "114.86284",
         "0.7161791831357048"
        ],
        [
         "12",
         "13",
         "1862",
         "1057",
         "194160",
         "47034",
         "103.56298",
         "0.7161791831357048"
        ],
        [
         "13",
         "14",
         "1810",
         "910",
         "106826",
         "30145",
         "70.892353",
         "0.7295125164690381"
        ],
        [
         "14",
         "15",
         "1787",
         "900",
         "169093",
         "52164",
         "96.218647",
         "0.7161791831357048"
        ],
        [
         "15",
         "16",
         "1835",
         "968",
         "250800",
         "83111",
         "132.536603",
         "0.7161791831357048"
        ],
        [
         "16",
         "17",
         "2117",
         "1210",
         "97587",
         "74672",
         "88.986781",
         "0.7161791831357048"
        ],
        [
         "17",
         "18",
         "1922",
         "1029",
         "103130",
         "56579",
         "83.04292",
         "0.7161791831357048"
        ],
        [
         "18",
         "19",
         "2080",
         "1025",
         "81450",
         "34126",
         "51.426475",
         "0.7432147562582346"
        ],
        [
         "19",
         "20",
         "2410",
         "1576",
         "88667",
         "40295",
         "58.432572",
         "0.7113438735177867"
        ],
        [
         "20",
         "21",
         "1798",
         "936",
         "69646",
         "13391",
         "41.994702",
         "0.7861001317523058"
        ],
        [
         "21",
         "22",
         "2085",
         "1154",
         "115851",
         "39132",
         "77.708483",
         "0.7217861848296631"
        ]
       ],
       "shape": {
        "columns": 7,
        "rows": 22
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>step</th>\n",
       "      <th>input_tokens_meta_llm</th>\n",
       "      <th>output_tokens_meta_llm</th>\n",
       "      <th>input_tokens_downstream_llm</th>\n",
       "      <th>output_tokens_downstream_llm</th>\n",
       "      <th>time_elapsed</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1424</td>\n",
       "      <td>635</td>\n",
       "      <td>161831</td>\n",
       "      <td>29141</td>\n",
       "      <td>125.999972</td>\n",
       "      <td>0.762846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1627</td>\n",
       "      <td>880</td>\n",
       "      <td>568037</td>\n",
       "      <td>140056</td>\n",
       "      <td>238.084428</td>\n",
       "      <td>0.691850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1814</td>\n",
       "      <td>955</td>\n",
       "      <td>100754</td>\n",
       "      <td>41299</td>\n",
       "      <td>60.767496</td>\n",
       "      <td>0.737846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1775</td>\n",
       "      <td>916</td>\n",
       "      <td>130451</td>\n",
       "      <td>43164</td>\n",
       "      <td>70.440861</td>\n",
       "      <td>0.716179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1701</td>\n",
       "      <td>911</td>\n",
       "      <td>160556</td>\n",
       "      <td>64794</td>\n",
       "      <td>96.849998</td>\n",
       "      <td>0.714698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>1670</td>\n",
       "      <td>852</td>\n",
       "      <td>20320</td>\n",
       "      <td>8610</td>\n",
       "      <td>14.442060</td>\n",
       "      <td>0.796179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>1833</td>\n",
       "      <td>1039</td>\n",
       "      <td>54166</td>\n",
       "      <td>18740</td>\n",
       "      <td>31.208828</td>\n",
       "      <td>0.796179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>1684</td>\n",
       "      <td>894</td>\n",
       "      <td>168342</td>\n",
       "      <td>87674</td>\n",
       "      <td>111.092516</td>\n",
       "      <td>0.716179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1816</td>\n",
       "      <td>1005</td>\n",
       "      <td>104550</td>\n",
       "      <td>37804</td>\n",
       "      <td>73.218236</td>\n",
       "      <td>0.716179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>1736</td>\n",
       "      <td>850</td>\n",
       "      <td>55772</td>\n",
       "      <td>37234</td>\n",
       "      <td>46.204789</td>\n",
       "      <td>0.746179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>1843</td>\n",
       "      <td>917</td>\n",
       "      <td>55443</td>\n",
       "      <td>30974</td>\n",
       "      <td>45.989948</td>\n",
       "      <td>0.753755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>1882</td>\n",
       "      <td>966</td>\n",
       "      <td>166284</td>\n",
       "      <td>96439</td>\n",
       "      <td>114.862840</td>\n",
       "      <td>0.716179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>1862</td>\n",
       "      <td>1057</td>\n",
       "      <td>194160</td>\n",
       "      <td>47034</td>\n",
       "      <td>103.562980</td>\n",
       "      <td>0.716179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>1810</td>\n",
       "      <td>910</td>\n",
       "      <td>106826</td>\n",
       "      <td>30145</td>\n",
       "      <td>70.892353</td>\n",
       "      <td>0.729513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>1787</td>\n",
       "      <td>900</td>\n",
       "      <td>169093</td>\n",
       "      <td>52164</td>\n",
       "      <td>96.218647</td>\n",
       "      <td>0.716179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>1835</td>\n",
       "      <td>968</td>\n",
       "      <td>250800</td>\n",
       "      <td>83111</td>\n",
       "      <td>132.536603</td>\n",
       "      <td>0.716179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>2117</td>\n",
       "      <td>1210</td>\n",
       "      <td>97587</td>\n",
       "      <td>74672</td>\n",
       "      <td>88.986781</td>\n",
       "      <td>0.716179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>1922</td>\n",
       "      <td>1029</td>\n",
       "      <td>103130</td>\n",
       "      <td>56579</td>\n",
       "      <td>83.042920</td>\n",
       "      <td>0.716179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>2080</td>\n",
       "      <td>1025</td>\n",
       "      <td>81450</td>\n",
       "      <td>34126</td>\n",
       "      <td>51.426475</td>\n",
       "      <td>0.743215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>2410</td>\n",
       "      <td>1576</td>\n",
       "      <td>88667</td>\n",
       "      <td>40295</td>\n",
       "      <td>58.432572</td>\n",
       "      <td>0.711344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>1798</td>\n",
       "      <td>936</td>\n",
       "      <td>69646</td>\n",
       "      <td>13391</td>\n",
       "      <td>41.994702</td>\n",
       "      <td>0.786100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>2085</td>\n",
       "      <td>1154</td>\n",
       "      <td>115851</td>\n",
       "      <td>39132</td>\n",
       "      <td>77.708483</td>\n",
       "      <td>0.721786</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    step  input_tokens_meta_llm  output_tokens_meta_llm  \\\n",
       "0      1                   1424                     635   \n",
       "1      2                   1627                     880   \n",
       "2      3                   1814                     955   \n",
       "3      4                   1775                     916   \n",
       "4      5                   1701                     911   \n",
       "5      6                   1670                     852   \n",
       "6      7                   1833                    1039   \n",
       "7      8                   1684                     894   \n",
       "8      9                   1816                    1005   \n",
       "9     10                   1736                     850   \n",
       "10    11                   1843                     917   \n",
       "11    12                   1882                     966   \n",
       "12    13                   1862                    1057   \n",
       "13    14                   1810                     910   \n",
       "14    15                   1787                     900   \n",
       "15    16                   1835                     968   \n",
       "16    17                   2117                    1210   \n",
       "17    18                   1922                    1029   \n",
       "18    19                   2080                    1025   \n",
       "19    20                   2410                    1576   \n",
       "20    21                   1798                     936   \n",
       "21    22                   2085                    1154   \n",
       "\n",
       "    input_tokens_downstream_llm  output_tokens_downstream_llm  time_elapsed  \\\n",
       "0                        161831                         29141    125.999972   \n",
       "1                        568037                        140056    238.084428   \n",
       "2                        100754                         41299     60.767496   \n",
       "3                        130451                         43164     70.440861   \n",
       "4                        160556                         64794     96.849998   \n",
       "5                         20320                          8610     14.442060   \n",
       "6                         54166                         18740     31.208828   \n",
       "7                        168342                         87674    111.092516   \n",
       "8                        104550                         37804     73.218236   \n",
       "9                         55772                         37234     46.204789   \n",
       "10                        55443                         30974     45.989948   \n",
       "11                       166284                         96439    114.862840   \n",
       "12                       194160                         47034    103.562980   \n",
       "13                       106826                         30145     70.892353   \n",
       "14                       169093                         52164     96.218647   \n",
       "15                       250800                         83111    132.536603   \n",
       "16                        97587                         74672     88.986781   \n",
       "17                       103130                         56579     83.042920   \n",
       "18                        81450                         34126     51.426475   \n",
       "19                        88667                         40295     58.432572   \n",
       "20                        69646                         13391     41.994702   \n",
       "21                       115851                         39132     77.708483   \n",
       "\n",
       "       score  \n",
       "0   0.762846  \n",
       "1   0.691850  \n",
       "2   0.737846  \n",
       "3   0.716179  \n",
       "4   0.714698  \n",
       "5   0.796179  \n",
       "6   0.796179  \n",
       "7   0.716179  \n",
       "8   0.716179  \n",
       "9   0.746179  \n",
       "10  0.753755  \n",
       "11  0.716179  \n",
       "12  0.716179  \n",
       "13  0.729513  \n",
       "14  0.716179  \n",
       "15  0.716179  \n",
       "16  0.716179  \n",
       "17  0.716179  \n",
       "18  0.743215  \n",
       "19  0.711344  \n",
       "20  0.786100  \n",
       "21  0.721786  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_grouped.plot(x=\"step\", y=\"score\", kind=\"line\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\schla\\\\git\\\\capo\\\\results\\\\sst-5\\\\llama\\\\CAPO\\\\seed44\\\\benchmark_experiment_sst-5_llama_CAPO_44\\\\cbc743c08d16c22ec7791bac5008d8c2381cb9c1cee4856ddc2f2fef761ef521\\\\tra.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[32]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m df_counts = \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mC:\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mUsers\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mschla\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mgit\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mcapo\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mresults\u001b[39m\u001b[33m\\\u001b[39m\u001b[33msst-5\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mllama\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mCAPO\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mseed44\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mbenchmark_experiment_sst-5_llama_CAPO_44\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mcbc743c08d16c22ec7791bac5008d8c2381cb9c1cee4856ddc2f2fef761ef521\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mtra.csv\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m df_counts = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_counts\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\schla\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\capo-JzHO-Y9b-py3.12\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\schla\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\capo-JzHO-Y9b-py3.12\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\schla\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\capo-JzHO-Y9b-py3.12\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\schla\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\capo-JzHO-Y9b-py3.12\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\schla\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\capo-JzHO-Y9b-py3.12\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\schla\\\\git\\\\capo\\\\results\\\\sst-5\\\\llama\\\\CAPO\\\\seed44\\\\benchmark_experiment_sst-5_llama_CAPO_44\\\\cbc743c08d16c22ec7791bac5008d8c2381cb9c1cee4856ddc2f2fef761ef521\\\\tra.csv'"
     ]
    }
   ],
   "source": [
    "df_counts = r\"C:\\Users\\schla\\git\\capo\\results\\sst-5\\llama\\CAPO\\seed44\\benchmark_experiment_sst-5_llama_CAPO_44\\cbc743c08d16c22ec7791bac5008d8c2381cb9c1cee4856ddc2f2fef761ef521\\tra.csv\"\n",
    "df_counts = pd.read_csv(df_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "prompt",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Unnamed: 0",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "block_id",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "b03f2c02-f8cc-49ea-9ea7-b49b86042255",
       "rows": [
        [
         "Analyze the sentiment expressed in this film critique. Categorize it as either veryNegative, negative, neutral, positive, or veryPositive, and present your answer between <final_answer> </final_answer> tags.\n\nInput: cold , pretentious , thoroughly dislikable study in sociopathy .\nOutput: <final_answer> negative </final_answer>\n\nInput: the work of an artist tormented by his heritage , using his storytelling ability to honor the many faceless victims .\nOutput: <final_answer> positive </final_answer>\n\n\nInput: ",
         "10",
         "10"
        ],
        [
         "Assess the emotional undertones in the given movie review and assign it to one of five distinct sentiment categories - veryNegative, negative, neutral, positive, or veryPositive - clearly demarcating your chosen classification with <final_answer> and </final_answer> to signify the review's overall sentiment.\n\nconforms itself with creating a game of ` who 's who ' ... where the characters ' moves are often more predictable than their consequences .\n<|start_header_id|>assistant<|end_header_id|>\n\nThe given review seems to imply that the movie is somewhat lacking in originality and unpredictability, as it creates a game of \"who's who\" with predictable character moves. This suggests a slightly negative tone. However, the criticism is not overly harsh, and there's no strong language used to condemn the movie outright. Therefore, the sentiment can be classified as negative, but not very negative, as it doesn't express extreme dissatisfaction.\n\n<final_answer> negative </final_answer>\n\nInput: what 's hard to understand is why anybody picked it up .\nOutput: <final_answer> veryNegative </final_answer>\n\n\nInput: ",
         "1",
         "1"
        ],
        [
         "Assess the sentiment expressed in the given movie review and categorize it into one of five emotional tone categories: veryNegative, negative, neutral, positive, or veryPositive, ensuring your selected category is enclosed between the <final_answer> and </final_answer> tags for identification.\n\nInput: an almost unbearably morbid love story .\nOutput: <final_answer> veryNegative </final_answer>\n\nInput: not completely loveable -- but what underdog movie since the bad news bears has been ?\nOutput: <final_answer> negative </final_answer>\n\nInput: a comedy-drama of nearly epic proportions rooted in a sincere performance by the title character undergoing midlife crisis .\nOutput: <final_answer> veryPositive </final_answer>\n\n\nInput: ",
         "10",
         "10"
        ],
        [
         "Assess the sentiment expressed in the given movie review and categorize it into one of five emotional tone categories: veryNegative, negative, neutral, positive, or veryPositive, ensuring your selected category is enclosed within <final_answer> and </final_answer> tags for clear identification.\n\nInput: the film does n't have enough innovation or pizazz to attract teenagers , and it lacks the novel charm that made spy kids a surprising winner with both adults and younger audiences .\nOutput: <final_answer> veryNegative </final_answer>\n\nInput: not completely loveable -- but what underdog movie since the bad news bears has been ?\nOutput: <final_answer> negative </final_answer>\n\n\nInput: ",
         "4",
         "4"
        ],
        [
         "Assess the sentiment of a given movie review, determining whether it expresses a veryNegative, negative, neutral, positive, or veryPositive opinion, and encapsulate your assessment within <final_answer> and </final_answer> tags to denote the review's emotional tone.\n\nInput: it 's packed to bursting with incident , and with scores of characters , some fictional , some from history .\nOutput: <final_answer> neutral </final_answer>\n\nit has its faults , but it is a kind , unapologetic , sweetheart of a movie , and mandy moore leaves a positive impression .\n<|start_header_id|>assistant<|end_header_id|>\n\n<final_answer>positive</final_answer>\n\n\nInput: ",
         "10",
         "10"
        ],
        [
         "Assess the sentiment of a movie review by determining the emotional tone conveyed and assign it to one of five categories: veryNegative, negative, neutral, positive, or veryPositive, clearly marking the chosen category between <final_answer> and </final_answer> tags for identification.\n\nInput: try this obscenely bad dark comedy , so crass that it makes edward burns ' sidewalks of new york look like oscar wilde .\nOutput: <final_answer> negative </final_answer>\n\n\nInput: ",
         "3",
         "3"
        ],
        [
         "Assess the sentiment of a movie review, categorizing its emotional tone into one of five categories: veryNegative, negative, neutral, positive, or veryPositive, and encapsulate your classification within <final_answer> and </final_answer> tags to explicitly denote the review's sentiment.\n\nthe touch is generally light enough and the performances , for the most part , credible .\n<|start_header_id|>assistant<|end_header_id|>\n\n<final_answer> positive </final_answer>\n\nInput: kids will love its fantasy and adventure , and grownups should appreciate its whimsical humor .\nOutput: <final_answer> veryPositive </final_answer>\n\nInput: tsai has a well-deserved reputation as one of the cinema world 's great visual stylists , and in this film , every shot enhances the excellent performances .\nOutput: <final_answer> positive </final_answer>\n\n\nInput: ",
         "1",
         "1"
        ],
        [
         "Assess the sentiment of the given movie review, determining its emotional tone and classifying it into one of five categories: veryNegative, negative, neutral, positive, or veryPositive, and ensure your chosen category is enclosed within <final_answer> and </final_answer> tags for identification.\n\nInput: -lrb- a -rrb- devastatingly powerful and astonishingly vivid holocaust drama .\nOutput: <final_answer> veryPositive </final_answer>\n\nInput: you 'll know a star when you see one .\nOutput: <final_answer> positive </final_answer>\n\nInput: brian tufano 's handsome widescreen photography and paul grabowsky 's excellent music turn this fairly parochial melodrama into something really rather special .\nOutput: <final_answer> veryPositive </final_answer>\n\n\nInput: ",
         "10",
         "10"
        ],
        [
         "Assess the sentiment of the provided movie review and categorize it into one of five emotional categories: veryNegative, negative, neutral, positive, or veryPositive, clearly indicating your chosen classification between the <final_answer> and </final_answer> tags.\n\nInput: carrying this wafer-thin movie on his nimble shoulders , chan wades through putrid writing , direction and timing with a smile that says , ` if i stay positive , maybe i can channel one of my greatest pictures , drunken master . '\nOutput: <final_answer> negative </final_answer>\n\nInput: not completely loveable -- but what underdog movie since the bad news bears has been ?\nOutput: <final_answer> negative </final_answer>\n\n\nInput: ",
         "10",
         "10"
        ],
        [
         "Assess the tone of the provided film review and categorize it as one of the following: veryNegative, negative, neutral, positive, or veryPositive. Your final classification must appear between <final_answer> and </final_answer> tags.\n\nInput: such a wildly uneven hit-and-miss enterprise , you ca n't help suspecting that it was improvised on a day-to-day basis during production .\nOutput: <final_answer> negative </final_answer>\n\n\nInput: ",
         "10",
         "10"
        ],
        [
         "Assign a sentiment label to the provided movie review, selecting from a range of five emotional responses: veryNegative, negative, neutral, positive, and veryPositive, based on the language and tone used in the critique, and clearly indicate your chosen classification between the markers <final_answer> answer </final_answer> for efficient evaluation of the review's sentiment.\n\n\n\n\nInput: ",
         "3",
         "3"
        ],
        [
         "Classify the sentiment of a movie review into one of five categories - veryNegative, negative, neutral, positive, or veryPositive - and encapsulate your classification result within <final_answer> answer </final_answer> to facilitate a rapid assessment of the cinematic critique's emotional tone.\n\nInput: to say that this vapid vehicle is downright doltish and uneventful is just as obvious as telling a country skunk that he has severe body odor .\nOutput: <final_answer> veryNegative </final_answer>\n\nInput: the powerful success of read my lips with such provocative material shows why , after only three films , director\\/co-writer jacques audiard , though little known in this country , belongs in the very top rank of french filmmakers .\nOutput: <final_answer> positive </final_answer>\n\n\nInput: ",
         "10",
         "10"
        ],
        [
         "Classify the sentiment of the given movie review into one of five emotional categories - veryNegative, negative, neutral, positive, or veryPositive - and encapsulate your answer within the <final_answer> and </final_answer> tags to denote the determined sentiment classification of the critique.\n\nInput: the obligatory break-ups and hook-ups do n't seem to have much emotional impact on the characters .\nOutput: <final_answer> neutral </final_answer>\n\nInput: williams creates a stunning , taxi driver-esque portrayal of a man teetering on the edge of sanity .\nOutput: <final_answer> veryPositive </final_answer>\n\n\nInput: ",
         "10",
         "10"
        ],
        [
         "Determine the emotional tone of the following movie critique. Is it veryNegative, negative, neutral, positive, or veryPositive? Your classification must be provided between <final_answer> and </final_answer> markers.\n\n\n\n\nInput: ",
         "10",
         "10"
        ],
        [
         "Evaluate the emotional content of the following film review and classify it into one of five sentiment categories: veryNegative, negative, neutral, positive, or veryPositive. Your classification must be provided between <final_answer> and </final_answer> markers.\n\nInput: you 'll know a star when you see one .\nOutput: <final_answer> positive </final_answer>\n\nInput: it 's virtually impossible to like any of these despicable characters .\nOutput: <final_answer> negative </final_answer>\n\n\nInput: ",
         "10",
         "10"
        ],
        [
         "Evaluate the emotional tone conveyed in a film review and categorize it into one of five sentiment categories: veryNegative, negative, neutral, positive, or veryPositive. Your response should be formatted as follows: <final_answer> selected_sentiment </final_answer>, where selected_sentiment represents the sentiment label that best captures the overall sentiment of the review, ranging from veryNegative to veryPositive.\n\nInput: ` like a child with an important message to tell ... -lrb- skins ' -rrb- faults are easy to forgive because the intentions are lofty . '\nOutput: <final_answer> neutral </final_answer>\n\nInput: the work of an artist tormented by his heritage , using his storytelling ability to honor the many faceless victims .\nOutput: <final_answer> positive </final_answer>\n\nInput: tsai has a well-deserved reputation as one of the cinema world 's great visual stylists , and in this film , every shot enhances the excellent performances .\nOutput: <final_answer> positive </final_answer>\n\n\nInput: ",
         "10",
         "10"
        ],
        [
         "Evaluate the emotional tone of a movie review and categorize it into one of five sentiment levels - veryNegative, negative, neutral, positive, or veryPositive - then encapsulate your classification between <final_answer> and </final_answer> tags to clearly indicate the sentiment of the review.\n\n\n\n\nInput: ",
         "10",
         "10"
        ],
        [
         "Evaluate the emotional tone of the given movie review and assign it to one of five distinct sentiment classifications: veryNegative, negative, neutral, positive, or veryPositive. Respond with your classification enclosed within <final_answer> and </final_answer> tags, such as <final_answer> answer </final_answer>, to clearly indicate your chosen sentiment category.\n\n\n\n\nInput: ",
         "10",
         "10"
        ],
        [
         "Evaluate the emotional tone of the given movie review and assign it to one of five sentiment categories: veryNegative, negative, neutral, positive, or veryPositive, then encapsulate your chosen category within the <final_answer> answer </final_answer> tags to facilitate a straightforward assessment of the review's sentiment and its evoked emotional response.\n\nconforms itself with creating a game of ` who 's who ' ... where the characters ' moves are often more predictable than their consequences .\n<|start_header_id|>assistant<|end_header_id|>\n\nThe given movie review seems to convey a sense of predictability and lack of surprise, which might indicate a slightly negative tone. The phrase \"more predictable than their consequences\" suggests that the reviewer found the plot or character actions to be somewhat expected, which could detract from the overall viewing experience. However, the tone does not seem to be extremely harsh or critical. Therefore, the sentiment category that best fits this review is \"negative\".\n\n<final_answer> negative </final_answer>\n\nInput: it 's packed to bursting with incident , and with scores of characters , some fictional , some from history .\nOutput: <final_answer> neutral </final_answer>\n\nInput: i loved this film .\nOutput: <final_answer> veryPositive </final_answer>\n\n\nInput: ",
         "1",
         "1"
        ],
        [
         "Evaluate the emotional tone of the given movie review and categorize it into one of five sentiment levels: veryNegative, negative, neutral, positive, or veryPositive, and then place your selected category between the <final_answer> and </final_answer> markers for identification.\n\nInput: it 's packed to bursting with incident , and with scores of characters , some fictional , some from history .\nOutput: <final_answer> neutral </final_answer>\n\nInput: the work of an artist tormented by his heritage , using his storytelling ability to honor the many faceless victims .\nOutput: <final_answer> positive </final_answer>\n\n\nInput: ",
         "1",
         "1"
        ],
        [
         "Evaluate the emotional undertone of the given cinematic critique and undertake a sentiment classification task, aiming to assign it to one of five distinct sentiment categories: veryNegative, negative, neutral, positive, or veryPositive, ensuring the selected category is encapsulated between <final_answer> and </final_answer> markers as the definitive sentiment label for the movie review in question.\n\nInput: to say that this vapid vehicle is downright doltish and uneventful is just as obvious as telling a country skunk that he has severe body odor .\nOutput: <final_answer> veryNegative </final_answer>\n\nInput: such a wildly uneven hit-and-miss enterprise , you ca n't help suspecting that it was improvised on a day-to-day basis during production .\nOutput: <final_answer> negative </final_answer>\n\n\nInput: ",
         "6",
         "6"
        ],
        [
         "Evaluate the emotional undertones of a movie review to categorize it into one of five sentiment categories - veryNegative, negative, neutral, positive, or veryPositive - and encapsulate your assessment within <final_answer> and </final_answer> markers to clearly indicate the review's sentiment, effectively gauging the critic's emotional stance on the film.\n\nInput: wo n't be placed in the pantheon of the best of the swashbucklers but it is a whole lot of fun and you get to see the one of the world 's best actors , daniel auteuil , have a whale of a good time .\nOutput: <final_answer> veryPositive </final_answer>\n\n\nInput: ",
         "3",
         "3"
        ],
        [
         "Evaluate the emotional undertones of a movie review to categorize its sentiment into one of five distinct categories: veryNegative, negative, neutral, positive, or veryPositive, and encapsulate your evaluation within <final_answer> and </final_answer> tags to clearly indicate the review's sentiment classification as veryNegative, negative, neutral, positive, or veryPositive.\n\n\n\n\nInput: ",
         "3",
         "3"
        ],
        [
         "Evaluate the sentiment of the provided movie review, assigning it to one of five distinct emotional categories: veryNegative, negative, neutral, positive, or veryPositive, and present your classification within the markers <final_answer> and </final_answer>, as in <final_answer> the chosen category </final_answer>, to accurately convey the reviewer's sentiment.\n\n\n\n\nInput: ",
         "3",
         "3"
        ],
        [
         "Evaluate the sentiment of the provided movie review, determining whether it conveys a veryNegative, negative, neutral, positive, or veryPositive emotional tone, and encapsulate your classification between the <final_answer> and </final_answer> tags.\n\n\n\n\nInput: ",
         "6",
         "6"
        ],
        [
         "For a given cinematic critique, assess its emotional tone and categorize it into one of five distinct sentiment groups: veryNegative, negative, neutral, positive, or veryPositive, and present the classification result in the specified format: <final_answer> selected_sentiment </final_answer>, where selected_sentiment represents the category that most accurately reflects the sentiment expressed in the movie review.\n\nInput: one of the more glaring signs of this movie 's servitude to its superstar is the way it skirts around any scenes that might have required genuine acting from ms. spears .\nOutput: <final_answer> veryNegative </final_answer>\n\nInput: cold , pretentious , thoroughly dislikable study in sociopathy .\nOutput: <final_answer> negative </final_answer>\n\n\nInput: ",
         "7",
         "7"
        ],
        [
         "For the provided movie review, determine the sentiment by categorizing it as veryNegative, negative, neutral, positive, or veryPositive, and then place your chosen sentiment category within the <final_answer> answer </final_answer> markers, allowing for an efficient evaluation of the review's sentiment and the emotional response it elicits.\n\nInput: gere gives a good performance in a film that does n't merit it .\nOutput: <final_answer> neutral </final_answer>\n\nInput: a serious movie with serious ideas .\nOutput: <final_answer> veryPositive </final_answer>\n\n\nInput: ",
         "10",
         "10"
        ],
        [
         "Given this movie critique, determine whether the overall sentiment is veryNegative, negative, neutral, positive, or veryPositive. Express your answer using the required format: <final_answer> chosen_category </final_answer>.\n\n\n\n\nInput: ",
         "10",
         "10"
        ],
        [
         "How would you describe the sentiment of this movie review? Choose from veryNegative, negative, neutral, positive, or veryPositive. Place your chosen category between <final_answer> and </final_answer>.\n\nInput: a treat for its depiction on not giving up on dreams when you 're a struggling nobody .\nOutput: <final_answer> positive </final_answer>\n\n\nInput: ",
         "10",
         "10"
        ],
        [
         "Please analyze this movie review and place it in one of five sentiment categories (veryNegative, negative, neutral, positive, or veryPositive). Format your response with <final_answer> followed by your categorization, then </final_answer>.\n\n\n\n\nInput: ",
         "10",
         "10"
        ],
        [
         "Quick sentiment check - is this movie review veryNegative, negative, neutral, positive, or veryPositive? Answer within <final_answer> </final_answer>.\n\nInput: the powerful success of read my lips with such provocative material shows why , after only three films , director\\/co-writer jacques audiard , though little known in this country , belongs in the very top rank of french filmmakers .\nOutput: <final_answer> positive </final_answer>\n\nInput: not completely loveable -- but what underdog movie since the bad news bears has been ?\nOutput: <final_answer> negative </final_answer>\n\n\nInput: ",
         "2",
         "2"
        ],
        [
         "Read the movie review and identify its sentiment. Select from these five categories: veryNegative, negative, neutral, positive, or veryPositive. Place your answer inside <final_answer> </final_answer>.\n\nInput: what 's hard to understand is why anybody picked it up .\nOutput: <final_answer> veryNegative </final_answer>\n\nInput: belongs in the too-hot-for-tv direct-to-video\\/dvd category , and this is why i have given it a one-star rating .\nOutput: <final_answer> negative </final_answer>\n\nInput: not completely loveable -- but what underdog movie since the bad news bears has been ?\nOutput: <final_answer> negative </final_answer>\n\n\nInput: ",
         "10",
         "10"
        ],
        [
         "Sentiment analysis task: categorize this cinema review as veryNegative, negative, neutral, positive, or veryPositive. Include your final classification within <final_answer> </final_answer>.\n\nInput: overall , it 's a very entertaining , thought-provoking film with a simple message : god is love .\nOutput: <final_answer> veryPositive </final_answer>\n\nInput: the inherent limitations of using a video game as the source material movie are once again made all too clear in this schlocky horror\\/action hybrid .\nOutput: <final_answer> negative </final_answer>\n\nInput: to say that this vapid vehicle is downright doltish and uneventful is just as obvious as telling a country skunk that he has severe body odor .\nOutput: <final_answer> veryNegative </final_answer>\n\n\nInput: ",
         "10",
         "10"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 33
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>block_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prompt</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Analyze the sentiment expressed in this film critique. Categorize it as either veryNegative, negative, neutral, positive, or veryPositive, and present your answer between &lt;final_answer&gt; &lt;/final_answer&gt; tags.\\n\\nInput: cold , pretentious , thoroughly dislikable study in sociopathy .\\nOutput: &lt;final_answer&gt; negative &lt;/final_answer&gt;\\n\\nInput: the work of an artist tormented by his heritage , using his storytelling ability to honor the many faceless victims .\\nOutput: &lt;final_answer&gt; positive &lt;/final_answer&gt;\\n\\n\\nInput:</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Assess the emotional undertones in the given movie review and assign it to one of five distinct sentiment categories - veryNegative, negative, neutral, positive, or veryPositive - clearly demarcating your chosen classification with &lt;final_answer&gt; and &lt;/final_answer&gt; to signify the review's overall sentiment.\\n\\nconforms itself with creating a game of ` who 's who ' ... where the characters ' moves are often more predictable than their consequences .\\n&lt;|start_header_id|&gt;assistant&lt;|end_header_id|&gt;\\n\\nThe given review seems to imply that the movie is somewhat lacking in originality and unpredictability, as it creates a game of \"who's who\" with predictable character moves. This suggests a slightly negative tone. However, the criticism is not overly harsh, and there's no strong language used to condemn the movie outright. Therefore, the sentiment can be classified as negative, but not very negative, as it doesn't express extreme dissatisfaction.\\n\\n&lt;final_answer&gt; negative &lt;/final_answer&gt;\\n\\nInput: what 's hard to understand is why anybody picked it up .\\nOutput: &lt;final_answer&gt; veryNegative &lt;/final_answer&gt;\\n\\n\\nInput:</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Assess the sentiment expressed in the given movie review and categorize it into one of five emotional tone categories: veryNegative, negative, neutral, positive, or veryPositive, ensuring your selected category is enclosed between the &lt;final_answer&gt; and &lt;/final_answer&gt; tags for identification.\\n\\nInput: an almost unbearably morbid love story .\\nOutput: &lt;final_answer&gt; veryNegative &lt;/final_answer&gt;\\n\\nInput: not completely loveable -- but what underdog movie since the bad news bears has been ?\\nOutput: &lt;final_answer&gt; negative &lt;/final_answer&gt;\\n\\nInput: a comedy-drama of nearly epic proportions rooted in a sincere performance by the title character undergoing midlife crisis .\\nOutput: &lt;final_answer&gt; veryPositive &lt;/final_answer&gt;\\n\\n\\nInput:</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Assess the sentiment expressed in the given movie review and categorize it into one of five emotional tone categories: veryNegative, negative, neutral, positive, or veryPositive, ensuring your selected category is enclosed within &lt;final_answer&gt; and &lt;/final_answer&gt; tags for clear identification.\\n\\nInput: the film does n't have enough innovation or pizazz to attract teenagers , and it lacks the novel charm that made spy kids a surprising winner with both adults and younger audiences .\\nOutput: &lt;final_answer&gt; veryNegative &lt;/final_answer&gt;\\n\\nInput: not completely loveable -- but what underdog movie since the bad news bears has been ?\\nOutput: &lt;final_answer&gt; negative &lt;/final_answer&gt;\\n\\n\\nInput:</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Assess the sentiment of a given movie review, determining whether it expresses a veryNegative, negative, neutral, positive, or veryPositive opinion, and encapsulate your assessment within &lt;final_answer&gt; and &lt;/final_answer&gt; tags to denote the review's emotional tone.\\n\\nInput: it 's packed to bursting with incident , and with scores of characters , some fictional , some from history .\\nOutput: &lt;final_answer&gt; neutral &lt;/final_answer&gt;\\n\\nit has its faults , but it is a kind , unapologetic , sweetheart of a movie , and mandy moore leaves a positive impression .\\n&lt;|start_header_id|&gt;assistant&lt;|end_header_id|&gt;\\n\\n&lt;final_answer&gt;positive&lt;/final_answer&gt;\\n\\n\\nInput:</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Assess the sentiment of a movie review by determining the emotional tone conveyed and assign it to one of five categories: veryNegative, negative, neutral, positive, or veryPositive, clearly marking the chosen category between &lt;final_answer&gt; and &lt;/final_answer&gt; tags for identification.\\n\\nInput: try this obscenely bad dark comedy , so crass that it makes edward burns ' sidewalks of new york look like oscar wilde .\\nOutput: &lt;final_answer&gt; negative &lt;/final_answer&gt;\\n\\n\\nInput:</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Assess the sentiment of a movie review, categorizing its emotional tone into one of five categories: veryNegative, negative, neutral, positive, or veryPositive, and encapsulate your classification within &lt;final_answer&gt; and &lt;/final_answer&gt; tags to explicitly denote the review's sentiment.\\n\\nthe touch is generally light enough and the performances , for the most part , credible .\\n&lt;|start_header_id|&gt;assistant&lt;|end_header_id|&gt;\\n\\n&lt;final_answer&gt; positive &lt;/final_answer&gt;\\n\\nInput: kids will love its fantasy and adventure , and grownups should appreciate its whimsical humor .\\nOutput: &lt;final_answer&gt; veryPositive &lt;/final_answer&gt;\\n\\nInput: tsai has a well-deserved reputation as one of the cinema world 's great visual stylists , and in this film , every shot enhances the excellent performances .\\nOutput: &lt;final_answer&gt; positive &lt;/final_answer&gt;\\n\\n\\nInput:</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Assess the sentiment of the given movie review, determining its emotional tone and classifying it into one of five categories: veryNegative, negative, neutral, positive, or veryPositive, and ensure your chosen category is enclosed within &lt;final_answer&gt; and &lt;/final_answer&gt; tags for identification.\\n\\nInput: -lrb- a -rrb- devastatingly powerful and astonishingly vivid holocaust drama .\\nOutput: &lt;final_answer&gt; veryPositive &lt;/final_answer&gt;\\n\\nInput: you 'll know a star when you see one .\\nOutput: &lt;final_answer&gt; positive &lt;/final_answer&gt;\\n\\nInput: brian tufano 's handsome widescreen photography and paul grabowsky 's excellent music turn this fairly parochial melodrama into something really rather special .\\nOutput: &lt;final_answer&gt; veryPositive &lt;/final_answer&gt;\\n\\n\\nInput:</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Assess the sentiment of the provided movie review and categorize it into one of five emotional categories: veryNegative, negative, neutral, positive, or veryPositive, clearly indicating your chosen classification between the &lt;final_answer&gt; and &lt;/final_answer&gt; tags.\\n\\nInput: carrying this wafer-thin movie on his nimble shoulders , chan wades through putrid writing , direction and timing with a smile that says , ` if i stay positive , maybe i can channel one of my greatest pictures , drunken master . '\\nOutput: &lt;final_answer&gt; negative &lt;/final_answer&gt;\\n\\nInput: not completely loveable -- but what underdog movie since the bad news bears has been ?\\nOutput: &lt;final_answer&gt; negative &lt;/final_answer&gt;\\n\\n\\nInput:</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Assess the tone of the provided film review and categorize it as one of the following: veryNegative, negative, neutral, positive, or veryPositive. Your final classification must appear between &lt;final_answer&gt; and &lt;/final_answer&gt; tags.\\n\\nInput: such a wildly uneven hit-and-miss enterprise , you ca n't help suspecting that it was improvised on a day-to-day basis during production .\\nOutput: &lt;final_answer&gt; negative &lt;/final_answer&gt;\\n\\n\\nInput:</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Assign a sentiment label to the provided movie review, selecting from a range of five emotional responses: veryNegative, negative, neutral, positive, and veryPositive, based on the language and tone used in the critique, and clearly indicate your chosen classification between the markers &lt;final_answer&gt; answer &lt;/final_answer&gt; for efficient evaluation of the review's sentiment.\\n\\n\\n\\n\\nInput:</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Classify the sentiment of a movie review into one of five categories - veryNegative, negative, neutral, positive, or veryPositive - and encapsulate your classification result within &lt;final_answer&gt; answer &lt;/final_answer&gt; to facilitate a rapid assessment of the cinematic critique's emotional tone.\\n\\nInput: to say that this vapid vehicle is downright doltish and uneventful is just as obvious as telling a country skunk that he has severe body odor .\\nOutput: &lt;final_answer&gt; veryNegative &lt;/final_answer&gt;\\n\\nInput: the powerful success of read my lips with such provocative material shows why , after only three films , director\\/co-writer jacques audiard , though little known in this country , belongs in the very top rank of french filmmakers .\\nOutput: &lt;final_answer&gt; positive &lt;/final_answer&gt;\\n\\n\\nInput:</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Classify the sentiment of the given movie review into one of five emotional categories - veryNegative, negative, neutral, positive, or veryPositive - and encapsulate your answer within the &lt;final_answer&gt; and &lt;/final_answer&gt; tags to denote the determined sentiment classification of the critique.\\n\\nInput: the obligatory break-ups and hook-ups do n't seem to have much emotional impact on the characters .\\nOutput: &lt;final_answer&gt; neutral &lt;/final_answer&gt;\\n\\nInput: williams creates a stunning , taxi driver-esque portrayal of a man teetering on the edge of sanity .\\nOutput: &lt;final_answer&gt; veryPositive &lt;/final_answer&gt;\\n\\n\\nInput:</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Determine the emotional tone of the following movie critique. Is it veryNegative, negative, neutral, positive, or veryPositive? Your classification must be provided between &lt;final_answer&gt; and &lt;/final_answer&gt; markers.\\n\\n\\n\\n\\nInput:</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Evaluate the emotional content of the following film review and classify it into one of five sentiment categories: veryNegative, negative, neutral, positive, or veryPositive. Your classification must be provided between &lt;final_answer&gt; and &lt;/final_answer&gt; markers.\\n\\nInput: you 'll know a star when you see one .\\nOutput: &lt;final_answer&gt; positive &lt;/final_answer&gt;\\n\\nInput: it 's virtually impossible to like any of these despicable characters .\\nOutput: &lt;final_answer&gt; negative &lt;/final_answer&gt;\\n\\n\\nInput:</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Evaluate the emotional tone conveyed in a film review and categorize it into one of five sentiment categories: veryNegative, negative, neutral, positive, or veryPositive. Your response should be formatted as follows: &lt;final_answer&gt; selected_sentiment &lt;/final_answer&gt;, where selected_sentiment represents the sentiment label that best captures the overall sentiment of the review, ranging from veryNegative to veryPositive.\\n\\nInput: ` like a child with an important message to tell ... -lrb- skins ' -rrb- faults are easy to forgive because the intentions are lofty . '\\nOutput: &lt;final_answer&gt; neutral &lt;/final_answer&gt;\\n\\nInput: the work of an artist tormented by his heritage , using his storytelling ability to honor the many faceless victims .\\nOutput: &lt;final_answer&gt; positive &lt;/final_answer&gt;\\n\\nInput: tsai has a well-deserved reputation as one of the cinema world 's great visual stylists , and in this film , every shot enhances the excellent performances .\\nOutput: &lt;final_answer&gt; positive &lt;/final_answer&gt;\\n\\n\\nInput:</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Evaluate the emotional tone of a movie review and categorize it into one of five sentiment levels - veryNegative, negative, neutral, positive, or veryPositive - then encapsulate your classification between &lt;final_answer&gt; and &lt;/final_answer&gt; tags to clearly indicate the sentiment of the review.\\n\\n\\n\\n\\nInput:</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Evaluate the emotional tone of the given movie review and assign it to one of five distinct sentiment classifications: veryNegative, negative, neutral, positive, or veryPositive. Respond with your classification enclosed within &lt;final_answer&gt; and &lt;/final_answer&gt; tags, such as &lt;final_answer&gt; answer &lt;/final_answer&gt;, to clearly indicate your chosen sentiment category.\\n\\n\\n\\n\\nInput:</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Evaluate the emotional tone of the given movie review and assign it to one of five sentiment categories: veryNegative, negative, neutral, positive, or veryPositive, then encapsulate your chosen category within the &lt;final_answer&gt; answer &lt;/final_answer&gt; tags to facilitate a straightforward assessment of the review's sentiment and its evoked emotional response.\\n\\nconforms itself with creating a game of ` who 's who ' ... where the characters ' moves are often more predictable than their consequences .\\n&lt;|start_header_id|&gt;assistant&lt;|end_header_id|&gt;\\n\\nThe given movie review seems to convey a sense of predictability and lack of surprise, which might indicate a slightly negative tone. The phrase \"more predictable than their consequences\" suggests that the reviewer found the plot or character actions to be somewhat expected, which could detract from the overall viewing experience. However, the tone does not seem to be extremely harsh or critical. Therefore, the sentiment category that best fits this review is \"negative\".\\n\\n&lt;final_answer&gt; negative &lt;/final_answer&gt;\\n\\nInput: it 's packed to bursting with incident , and with scores of characters , some fictional , some from history .\\nOutput: &lt;final_answer&gt; neutral &lt;/final_answer&gt;\\n\\nInput: i loved this film .\\nOutput: &lt;final_answer&gt; veryPositive &lt;/final_answer&gt;\\n\\n\\nInput:</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Evaluate the emotional tone of the given movie review and categorize it into one of five sentiment levels: veryNegative, negative, neutral, positive, or veryPositive, and then place your selected category between the &lt;final_answer&gt; and &lt;/final_answer&gt; markers for identification.\\n\\nInput: it 's packed to bursting with incident , and with scores of characters , some fictional , some from history .\\nOutput: &lt;final_answer&gt; neutral &lt;/final_answer&gt;\\n\\nInput: the work of an artist tormented by his heritage , using his storytelling ability to honor the many faceless victims .\\nOutput: &lt;final_answer&gt; positive &lt;/final_answer&gt;\\n\\n\\nInput:</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Evaluate the emotional undertone of the given cinematic critique and undertake a sentiment classification task, aiming to assign it to one of five distinct sentiment categories: veryNegative, negative, neutral, positive, or veryPositive, ensuring the selected category is encapsulated between &lt;final_answer&gt; and &lt;/final_answer&gt; markers as the definitive sentiment label for the movie review in question.\\n\\nInput: to say that this vapid vehicle is downright doltish and uneventful is just as obvious as telling a country skunk that he has severe body odor .\\nOutput: &lt;final_answer&gt; veryNegative &lt;/final_answer&gt;\\n\\nInput: such a wildly uneven hit-and-miss enterprise , you ca n't help suspecting that it was improvised on a day-to-day basis during production .\\nOutput: &lt;final_answer&gt; negative &lt;/final_answer&gt;\\n\\n\\nInput:</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Evaluate the emotional undertones of a movie review to categorize it into one of five sentiment categories - veryNegative, negative, neutral, positive, or veryPositive - and encapsulate your assessment within &lt;final_answer&gt; and &lt;/final_answer&gt; markers to clearly indicate the review's sentiment, effectively gauging the critic's emotional stance on the film.\\n\\nInput: wo n't be placed in the pantheon of the best of the swashbucklers but it is a whole lot of fun and you get to see the one of the world 's best actors , daniel auteuil , have a whale of a good time .\\nOutput: &lt;final_answer&gt; veryPositive &lt;/final_answer&gt;\\n\\n\\nInput:</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Evaluate the emotional undertones of a movie review to categorize its sentiment into one of five distinct categories: veryNegative, negative, neutral, positive, or veryPositive, and encapsulate your evaluation within &lt;final_answer&gt; and &lt;/final_answer&gt; tags to clearly indicate the review's sentiment classification as veryNegative, negative, neutral, positive, or veryPositive.\\n\\n\\n\\n\\nInput:</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Evaluate the sentiment of the provided movie review, assigning it to one of five distinct emotional categories: veryNegative, negative, neutral, positive, or veryPositive, and present your classification within the markers &lt;final_answer&gt; and &lt;/final_answer&gt;, as in &lt;final_answer&gt; the chosen category &lt;/final_answer&gt;, to accurately convey the reviewer's sentiment.\\n\\n\\n\\n\\nInput:</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Evaluate the sentiment of the provided movie review, determining whether it conveys a veryNegative, negative, neutral, positive, or veryPositive emotional tone, and encapsulate your classification between the &lt;final_answer&gt; and &lt;/final_answer&gt; tags.\\n\\n\\n\\n\\nInput:</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>For a given cinematic critique, assess its emotional tone and categorize it into one of five distinct sentiment groups: veryNegative, negative, neutral, positive, or veryPositive, and present the classification result in the specified format: &lt;final_answer&gt; selected_sentiment &lt;/final_answer&gt;, where selected_sentiment represents the category that most accurately reflects the sentiment expressed in the movie review.\\n\\nInput: one of the more glaring signs of this movie 's servitude to its superstar is the way it skirts around any scenes that might have required genuine acting from ms. spears .\\nOutput: &lt;final_answer&gt; veryNegative &lt;/final_answer&gt;\\n\\nInput: cold , pretentious , thoroughly dislikable study in sociopathy .\\nOutput: &lt;final_answer&gt; negative &lt;/final_answer&gt;\\n\\n\\nInput:</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>For the provided movie review, determine the sentiment by categorizing it as veryNegative, negative, neutral, positive, or veryPositive, and then place your chosen sentiment category within the &lt;final_answer&gt; answer &lt;/final_answer&gt; markers, allowing for an efficient evaluation of the review's sentiment and the emotional response it elicits.\\n\\nInput: gere gives a good performance in a film that does n't merit it .\\nOutput: &lt;final_answer&gt; neutral &lt;/final_answer&gt;\\n\\nInput: a serious movie with serious ideas .\\nOutput: &lt;final_answer&gt; veryPositive &lt;/final_answer&gt;\\n\\n\\nInput:</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Given this movie critique, determine whether the overall sentiment is veryNegative, negative, neutral, positive, or veryPositive. Express your answer using the required format: &lt;final_answer&gt; chosen_category &lt;/final_answer&gt;.\\n\\n\\n\\n\\nInput:</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>How would you describe the sentiment of this movie review? Choose from veryNegative, negative, neutral, positive, or veryPositive. Place your chosen category between &lt;final_answer&gt; and &lt;/final_answer&gt;.\\n\\nInput: a treat for its depiction on not giving up on dreams when you 're a struggling nobody .\\nOutput: &lt;final_answer&gt; positive &lt;/final_answer&gt;\\n\\n\\nInput:</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Please analyze this movie review and place it in one of five sentiment categories (veryNegative, negative, neutral, positive, or veryPositive). Format your response with &lt;final_answer&gt; followed by your categorization, then &lt;/final_answer&gt;.\\n\\n\\n\\n\\nInput:</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Quick sentiment check - is this movie review veryNegative, negative, neutral, positive, or veryPositive? Answer within &lt;final_answer&gt; &lt;/final_answer&gt;.\\n\\nInput: the powerful success of read my lips with such provocative material shows why , after only three films , director\\/co-writer jacques audiard , though little known in this country , belongs in the very top rank of french filmmakers .\\nOutput: &lt;final_answer&gt; positive &lt;/final_answer&gt;\\n\\nInput: not completely loveable -- but what underdog movie since the bad news bears has been ?\\nOutput: &lt;final_answer&gt; negative &lt;/final_answer&gt;\\n\\n\\nInput:</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Read the movie review and identify its sentiment. Select from these five categories: veryNegative, negative, neutral, positive, or veryPositive. Place your answer inside &lt;final_answer&gt; &lt;/final_answer&gt;.\\n\\nInput: what 's hard to understand is why anybody picked it up .\\nOutput: &lt;final_answer&gt; veryNegative &lt;/final_answer&gt;\\n\\nInput: belongs in the too-hot-for-tv direct-to-video\\/dvd category , and this is why i have given it a one-star rating .\\nOutput: &lt;final_answer&gt; negative &lt;/final_answer&gt;\\n\\nInput: not completely loveable -- but what underdog movie since the bad news bears has been ?\\nOutput: &lt;final_answer&gt; negative &lt;/final_answer&gt;\\n\\n\\nInput:</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sentiment analysis task: categorize this cinema review as veryNegative, negative, neutral, positive, or veryPositive. Include your final classification within &lt;final_answer&gt; &lt;/final_answer&gt;.\\n\\nInput: overall , it 's a very entertaining , thought-provoking film with a simple message : god is love .\\nOutput: &lt;final_answer&gt; veryPositive &lt;/final_answer&gt;\\n\\nInput: the inherent limitations of using a video game as the source material movie are once again made all too clear in this schlocky horror\\/action hybrid .\\nOutput: &lt;final_answer&gt; negative &lt;/final_answer&gt;\\n\\nInput: to say that this vapid vehicle is downright doltish and uneventful is just as obvious as telling a country skunk that he has severe body odor .\\nOutput: &lt;final_answer&gt; veryNegative &lt;/final_answer&gt;\\n\\n\\nInput:</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Unnamed: 0  block_id\n",
       "prompt                                                                  \n",
       "Analyze the sentiment expressed in this film cr...          10        10\n",
       "Assess the emotional undertones in the given mo...           1         1\n",
       "Assess the sentiment expressed in the given mov...          10        10\n",
       "Assess the sentiment expressed in the given mov...           4         4\n",
       "Assess the sentiment of a given movie review, d...          10        10\n",
       "Assess the sentiment of a movie review by deter...           3         3\n",
       "Assess the sentiment of a movie review, categor...           1         1\n",
       "Assess the sentiment of the given movie review,...          10        10\n",
       "Assess the sentiment of the provided movie revi...          10        10\n",
       "Assess the tone of the provided film review and...          10        10\n",
       "Assign a sentiment label to the provided movie ...           3         3\n",
       "Classify the sentiment of a movie review into o...          10        10\n",
       "Classify the sentiment of the given movie revie...          10        10\n",
       "Determine the emotional tone of the following m...          10        10\n",
       "Evaluate the emotional content of the following...          10        10\n",
       "Evaluate the emotional tone conveyed in a film ...          10        10\n",
       "Evaluate the emotional tone of a movie review a...          10        10\n",
       "Evaluate the emotional tone of the given movie ...          10        10\n",
       "Evaluate the emotional tone of the given movie ...           1         1\n",
       "Evaluate the emotional tone of the given movie ...           1         1\n",
       "Evaluate the emotional undertone of the given c...           6         6\n",
       "Evaluate the emotional undertones of a movie re...           3         3\n",
       "Evaluate the emotional undertones of a movie re...           3         3\n",
       "Evaluate the sentiment of the provided movie re...           3         3\n",
       "Evaluate the sentiment of the provided movie re...           6         6\n",
       "For a given cinematic critique, assess its emot...           7         7\n",
       "For the provided movie review, determine the se...          10        10\n",
       "Given this movie critique, determine whether th...          10        10\n",
       "How would you describe the sentiment of this mo...          10        10\n",
       "Please analyze this movie review and place it i...          10        10\n",
       "Quick sentiment check - is this movie review ve...           2         2\n",
       "Read the movie review and identify its sentimen...          10        10\n",
       "Sentiment analysis task: categorize this cinema...          10        10"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_counts.groupby(\"prompt\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Evaluate the emotional tone of the given movie review and assign it to one of five sentiment categories: veryNegative, negative, neutral, positive, or veryPositive, then encapsulate your chosen category within the <final_answer> answer </final_answer> tags to facilitate a straightforward assessment of the review's sentiment and its evoked emotional response.\n",
    "\n",
    "conforms itself with creating a game of ` who 's who ' ... where the characters ' moves are often more predictable than their consequences .\n",
    "<|start_header_id|>assistant<|end_header_id|>\n",
    "\n",
    "The given movie review seems to convey a sense of predictability and lack of surprise, which might indicate a slightly negative tone. The phrase \"more predictable than their consequences\" suggests that the reviewer found the plot or character actions to be somewhat expected, which could detract from the overall viewing experience. However, the tone does not seem to be extremely harsh or critical. Therefore, the sentiment category that best fits this review is \"negative\".\n",
    "\n",
    "<final_answer> negative </final_answer>\n",
    "\n",
    "Input: it 's packed to bursting with incident , and with scores of characters , some fictional , some from history .\n",
    "Output: <final_answer> neutral </final_answer>\n",
    "\n",
    "Input: i loved this film .\n",
    "Output: <final_answer> veryPositive </final_answer>\n",
    "\n",
    "\n",
    "Input: "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capo-JzHO-Y9b-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
