\section{CAPO - Pseudo Algorithm}

\begin{algorithm}[h]
    \caption{CAPO: Cost-Aware Prompt Optimization}
    \begin{algorithmic}[1]
        \Require Dataset $\mathcal{D} = \{(X_i, y_i)\}_{i=1}^n$, Meta-LLM $\Phi(x)$,
        Downstream LLM $\phi(x)$, Initial instructions $\Lambda = \{\lambda_1, \dots, \lambda_p\}$,
        Population size $p$, Block size $b$, Number of iterations $n$, Number of crossovers per iteration $c$
        \For{$\lambda \in \Lambda$}
        \State $\text{num\_shots} \sim \text{U}(\text{lower}, \text{upper})$
        \State $\xi \gets \text{sample}(X, \text{num\_shots})$ \Comment{Sample few shot examples}
        \State $\theta \gets \phi(\lambda||\xi)$   \Comment{Generate few shots with reasoning}
        \State $\pi \gets (\lambda, \theta)$
        \State $\Pi \gets \Pi\text{.append}(\pi)$
        \EndFor
        \State Divide dataset $\mathcal{D}$ into blocks $\mathcal{B} = \{B_1, ..., B_k\}$ where $|B_i| = b$
        \For{$i=1$ to $n$}
        \State $\Pi_{\text{off}} \gets \text{cross\_over}(\Pi, c)$
        \State $\Pi_{\text{off}} \gets \text{mutate}(\Pi_{\text{off}})$
        \State $\Pi \gets \text{do\_racing}(\Pi \cup \Pi_\text{off}, k=p)$
        \EndFor
        \State $\text{best\_prompt} \gets \text{do\_racing}(\Pi, k=1)$
        \State \Return best\_prompt
    \end{algorithmic}
\end{algorithm}

\noindent Is reasoning for few-shots always necessary? Maybe this is not important for simple tasks and costs a lot of tokens. (Idea: some few shot examples can be included without reasoning)\\
\newpage

\begin{algorithm}[h]
    \caption{cross\_over}
    \begin{algorithmic}[1]
        \Require Population $\Pi$, Meta-LLM $\Phi(x)$, Cross-Over-Meta-Prompt $\lambda_{\text{C}}$, Number of crossovers $c$
        \State $\Pi_{\text{off}} \gets  []$
        \For{$j=1$ to $c$}
        \State $P_1 \gets \text{sample}(\Pi, 1)$ \Comment{$P_1 = (\lambda_1, \theta_1)$}
        \State $P_2 \gets \text{sample}(\Pi, 1)$ \Comment{$P_2 = (\lambda_2, \theta_2)$}
        \State $\lambda_{\text{off}} \gets \Phi(\lambda_{\text{C}} || \lambda_1 || \lambda_2)$ \Comment{Let Meta-LLM cross over the prompts}
        \State $\theta_{\text{off},j} \gets \text{sample}(\theta_1 \cup \theta_2, \left\lfloor\frac{|\theta_1|+|\theta_2|}{2}\right\rfloor)$ \Comment{Sample from all few-shot examples}
        \State $\pi_{\text{off},j} \gets (\lambda_{\text{off},j}, \theta_{\text{off},j})$
        \State $\Pi_{\text{off}} \gets \Pi_{\text{off}}.\text{append}(\pi_{\text{off},j})$
        \EndFor
        \State \Return $\Pi_{\text{off}}$
    \end{algorithmic}
\end{algorithm}

\noindent Currently we do a random parent selection. In EvoPrompt they do a roulette wheel selection based on the fitness scores. This would require us to find a way of already having scores here.\\

\begin{algorithm}[h]
    \caption{mutate}
    \begin{algorithmic}[1]
        \Require Population of offsprings $\Pi_{\text{off}}$, Meta-LLM $\Phi(x)$, Mutation-Meta-Prompt $\lambda_{\text{M}}$, Dataset samples $X$
        \For{$\pi_{\text{off}} \in \Pi_{\text{off}}$}
        \State $\lambda_{\text{off}} \gets \Phi(\lambda_{\text{M}} || \lambda_{\text{off}})$
        \State $\text{num\_shots} \sim \text{U}(\text{lower}, \text{upper})$
        \State $\text{num\_new\_shots} \sim \text{U}(\text{lower}, \text{num\_shots})$
        \State $\xi \gets \text{sample}(X, \text{num\_new\_shots})$ \Comment{Sample new few shot examples}
        \State $\theta_\text{new} \gets \phi(\lambda_\text{off}||\xi)$   \Comment{Generate few shots with reasoning}
        \State $\theta_\text{old} \gets \text{sample}(\theta_{\text{off}}, \text{num\_shots} - \text{num\_new\_shots})$
        \State $\theta \gets \theta_{\text{old}} \cup \theta_{\text{new}}$
        \State $\theta \gets \text{shuffle}(\theta)$
        \State $\pi_\text{off} \gets (\lambda_\text{off}, \theta)$
        \EndFor
        \State \Return $\Pi_{\text{off}}$
    \end{algorithmic}
\end{algorithm}

\noindent We have to clarify where the new few-shot examples are coming from.\\
\noindent Extra Split:\\
+ no data leakage (fair, comparable assessment of prompts)\\
- constrained pool of few-shot examples (how to get this pool?) - potentially smaller dev Split\\

\noindent From Train Split:\\
- data leakage (prompts that contain eval data point already as few-shot examples which are already confirmed as correct have advantages)\\
+ we can use the full train set\\

\clearpage
\begin{algorithm}
    \caption{do\_racing}
    \begin{algorithmic}[1]
        \Require Prompts $\Pi$, Top-k $k$, blocks $\mathcal{B}$, Downstream LLM $\phi(x)$, Max number of evaluated blocks max\_n\_blocks\_eval
        \State $i \gets 0$
        \State scores $\gets [0]*\text{len}(\Pi)$
        \State $\text{shuffle}(\mathcal{B})$ \Comment{Whether to shuffle is left as a HP}
        \While{$\text{len}(\Pi) > k \ \land \ i < \text{max\_n\_blocks\_eval}$}
        \State $i \gets i + 1$
        \State $\text{scores} \gets \frac{1}{i}\left(\text{evaluate}(\Pi, B_i) + (i-1)*\text{scores}\right)$ \Comment{Already evaluated blocks are cached}
        \State $\Pi \gets \text{racing\_elimination}(\Pi, \text{scores}, \alpha, k)$
        \EndWhile
        \If{$\text{len}(\Pi) > k$}
        \State $\Pi \gets \text{top\_k}(\Pi)$ \Comment{Make sure to return only k prompts}
        \EndIf
        \State \Return $\Pi$
    \end{algorithmic}
\end{algorithm}

\begin{algorithm}
    \caption{racing\_elimination}
    \begin{algorithmic}[1]
        \Require Survivors $\Pi$, scores $S$,  confidence level $\alpha$, top-k $k$
        \State $c_\alpha \gets \text{getCriticalValue}(\alpha)$
        \For{$\pi_i \in \Pi$}
        \State n\_sig\_better $ \gets \sum_{j \neq i} \mathbf{1}_{\left[\text{getTestStatistic}(s_j, s_i) > c_{\alpha}\right]} $
        \If{n\_sig\_better $\geq k$}
        \State  $\Pi$ $\gets$  $\Pi$ $\setminus \{\pi_i\}$ \Comment{Eliminate $\pi_i$}
        \EndIf
        \EndFor
        \State \Return  $\Pi$
    \end{algorithmic}
\end{algorithm}


Potential test statistics:
\begin{itemize}
    \item Friedmann test (with post-hoc tests) like mentioned in irace paper
    \item Two-sided t-test like mentioned in irace paper
    \item Hoeffding races: $\varepsilon = \sqrt{\frac{B^2\log(2/\delta)}{2n}}$
\end{itemize} 

Further Ideas:\\
\textbf{Multi-objective} optimization (predictive performance and cost(e.g. prompt length)) - how to consider both objectives in the test statistic? -> only then we are ``cost aware'' (also reduces cost of optimization because of shorter prompt, fewer few-shot examples, ...)\\
\textbf{Multi-fidelity} can be e.g. done by first using a smaller model to determine a promising population and then continue with a larger model.\\