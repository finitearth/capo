{"experiment_name": "ablation_experiment_gsm8k_llama_CAPO_zero_shot_44", "random_seed": 44, "budget_per_run": 5000000, "output_dir": "results/ablation_results//gsm8k/llama/CAPO_zero_shot/seed44/", "generic_init_prompts": false, "dataset": "gsm8k", "model": "vllm-shuyuej/Llama-3.3-70B-Instruct-GPTQ", "model_revision": "3a7f7f7d46e362291821aaefb0a38b632f1190a8", "max_model_len": 2048, "batch_size": null, "model_storage_path": "../models/", "optimizer": "CAPO", "n_steps": 999, "population_size": 10, "n_eval_samples": null, "evoprompt_ga_template": "standard", "block_size": 30, "length_penalty": 0.05, "crossovers_per_iter": 4, "upper_shots": 0, "max_n_blocks_eval": 10, "alpha": 0.2, "shuffle_blocks_per_iter": false, "max_num_instructions": 20, "max_instructions_per_step": 8, "num_few_shots": 3}